{"version":"1","records":[{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers a workflow for using Xarray and xbatcher for deep learning applications. Specifically, it demonstrates a reusable workflow for recreating an xarray dataset from a deep learning model’s output, which can be used for further analysis or visualization.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"content":"This cookbook will be useful for data scientists and machine learning practitioners who want to leverage the power of xarray and xbatcher for their deep learning workflows. By the end of this cookbook, you will have gained skills in loading and processing Xarray datasets into a format suitable for deep learning using xbatcher and furthermore, you will learn how to recreate an Xarray dataset from the output of a deep learning model.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"content":"Keenan Ganz, \n\nNabin Kalauni","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections - “xbatcher Fundamentals” and “Example Workflow”. The first section covers the foundational concepts and tools needed to work with xbatcher and xarray, while the second section provides a practical example of how to use these tools in a complete end-to-end workflow.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"type":"lvl3","url":"/#xbatcher-fundamentals","position":10},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"content":"The foundational content includes an overview of xbatcher, its key features, and how it integrates with xarray for efficient data handling in deep learning workflows. The first chapter covers using xbatcher to create batches of data from an xarray dataset whereas the second chapter focuses on recreating an xarray dataset from the output of a deep learning model.","type":"content","url":"/#xbatcher-fundamentals","position":11},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"type":"lvl3","url":"/#example-workflow","position":12},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"content":"Example workflow includes using xbatcher to create batches of data from an xarray dataset (ASTER Global Digital Elevation model), training an Autoencoder on this data, and then using xbatcher again to reassemble the model’s output into a new xarray dataset.","type":"content","url":"/#example-workflow","position":13},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/xbatcher-deep-learning repository: git clone https://github.com/ProjectPythia/xbatcher-deep-learning.git\n\nMove into the xbatcher-deep-learning directorycd xbatcher-deep-learning\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Infer model on array"},"type":"lvl1","url":"/notebooks/inference-testing","position":0},{"hierarchy":{"lvl1":"Infer model on array"},"content":"\n\n","type":"content","url":"/notebooks/inference-testing","position":1},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/inference-testing#imports","position":2},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"content":"\n\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, predict_on_array\n\n","type":"content","url":"/notebooks/inference-testing#imports","position":3},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-array-size-function","position":4},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"content":"\n\n%%writefile test_get_array_size.py\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, _get_resample_factor\n\n%%writefile -a test_get_array_size.py\n\n@pytest.fixture\ndef bgen_fixture() -> xbatcher.BatchGenerator:\n    data = xr.DataArray(\n        data=np.random.rand(100, 100, 10),\n        dims=(\"x\", \"y\", \"t\"),\n        coords={\n            \"x\": np.arange(100),\n            \"y\": np.arange(100),\n            \"t\": np.arange(10),\n        }\n    )\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=10),\n        input_overlap=dict(x=5, y=5),\n    )\n    return bgen\n\n@pytest.mark.parametrize(\n    \"case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output\",\n    [\n        (\n            \"Resampling only: Downsample x, Upsample y\",\n            {'x': 5, 'y': 20},  \n            [],\n            [],\n            ['x', 'y'],\n            {'x': 50, 'y': 200} \n        ),\n        (\n            \"New dimensions only: Add a 'channel' dimension\",\n            {'channel': 3},\n            ['channel'],\n            [],\n            [],\n            {'channel': 3}\n        ),\n        (\n            \"Mixed: Resample x, add new channel dimension and keep t as core\",\n            {'x': 30, 'channel': 12, 't': 10}, \n            ['channel'],\n            ['t'],\n            ['x'],\n            {'x': 300, 'channel': 12, 't': 10} \n        ),\n        (\n            \"Identity resampling (ratio=1)\",\n            {'x': 10, 'y': 10},\n            [],\n            [],\n            ['x', 'y'],\n            {'x': 100, 'y': 100} \n        ),\n        (\n            \"Core dims only: 't' is a core dim\",\n            {'t': 10},\n            [], \n            ['t'], \n            [],\n            {'t': 10}\n        ),\n    ]\n)\ndef test_get_output_array_size_scenarios(\n    bgen_fixture,  # The fixture is passed as an argument\n    case_description,\n    output_tensor_dim,\n    new_dim,\n    core_dim,\n    resample_dim,\n    expected_output\n):\n    \"\"\"\n    Tests various valid scenarios for calculating the output array size.\n    The `case_description` parameter is not used in the code but helps make\n    test results more readable.\n    \"\"\"\n    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture\n    result = _get_output_array_size(\n        bgen=bgen_fixture,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        core_dim=core_dim,\n        resample_dim=resample_dim\n    )\n    \n    assert result == expected_output, f\"Failed on case: {case_description}\"\n\n%%writefile -a test_get_array_size.py\n\ndef test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a core_dim size doesn't match the source.\"\"\"\n    with pytest.raises(ValueError, match=\"does not equal the source data array size\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'t': 99}, new_dim=[], core_dim=['t'], resample_dim=[]\n        )\n\ndef test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a dimension is not specified in any category.\"\"\"\n    with pytest.raises(ValueError, match=\"must be specified in one of\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'x': 10}, new_dim=[], core_dim=[], resample_dim=[]\n        )\n\ndef test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):\n    \"\"\"Tests AssertionError when the resample ratio is not an integer or its inverse.\"\"\"\n    with pytest.raises(AssertionError, match=\"must be an integer or its inverse\"):\n        # 15 / 10 = 1.5, which is not a valid ratio\n        _get_resample_factor(bgen_fixture, output_tensor_dim={'x': 15}, resample_dim=['x'])\n\n!pytest -v test_get_array_size.py\n\n","type":"content","url":"/notebooks/inference-testing#testing-the-array-size-function","position":5},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":6},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"content":"\n\n%%writefile test_predict_on_array.py\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, _resample_coordinate\nfrom functions import predict_on_array, _get_resample_factor\nfrom dummy_models import Identity, MeanAlongDim, SubsetAlongAxis, ExpandAlongAxis, AddAxis\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import *\nfrom dummy_models import *\n\ninput_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)\ninput_tensor[0,0,:]\n\nmodel = ExpandAlongAxis(1, 2)\nmodel(input_tensor).shape\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.fixture\ndef map_dataset_fixture() -> MapDataset:\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10).astype(np.float32),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20, dtype=float), \"y\": np.arange(10, dtype=float)},\n    )\n    bgen = xbatcher.BatchGenerator(data, input_dims=dict(x=10, y=5), input_overlap=dict(x=2, y=2))\n    return MapDataset(bgen)\n\n\ndata = xr.DataArray(\n    data=np.arange(20 * 10).reshape(20, 10),\n    dims=(\"x\", \"y\"),\n    coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n).astype(float)\n\nbgen = xbatcher.BatchGenerator(\n    data,\n    input_dims=dict(x=10, y=5),\n    input_overlap=dict(x=2, y=2)\n)\n\nds = MapDataset(bgen)\n\ndata\n\nds[1]\n\noutput_tensor_dim = {'x': 20, 'y': 5}\nresample_dim = ['x', 'y']\ncore_dim = []\nnew_dim = []\n\nds[0].shape\n\nmodel(ds[0]).shape\n\nimport functions\nfrom importlib import reload\nreload(functions)\nresult = functions.predict_on_array(\n    ds,\n    model,\n    output_tensor_dim=output_tensor_dim,\n    new_dim=new_dim,\n    core_dim=core_dim,\n    resample_dim=resample_dim,\n    batch_size=4\n)\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\"factor, mode, expected\", [\n    (2.0, \"edges\", np.arange(0, 10, 0.5)),\n    (0.5, \"edges\", np.arange(0, 10, 2.0)),\n])\ndef test_resample_coordinate(factor, mode, expected):\n    coord = xr.DataArray(np.arange(10, dtype=float), dims=\"x\")\n    resampled = _resample_coordinate(coord, factor, mode)\n    np.testing.assert_allclose(resampled, expected)\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\n    \"model, output_tensor_dim, new_dim, core_dim, resample_dim, manual_transform\",\n    [\n        # Case 1: Identity - No change\n        (\n            Identity(),\n            {'x': 10, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.data\n        ),\n        # Case 2: ExpandAlongAxis - Upsampling\n        (\n            ExpandAlongAxis(ax=1, n_repeats=2), # ax=1 is 'x'\n            {'x': 20, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.data.repeat(2, axis=0) # axis=0 in the 2D numpy array\n        ),\n        # Case 3: SubsetAlongAxis - Coarsening\n        (\n            SubsetAlongAxis(ax=1, n=5), # ax=1 is 'x'\n            {'x': 5, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.isel(x=slice(0, 5)).data\n        ),\n        # Case 4: MeanAlongDim - Dimension reduction\n        (\n            MeanAlongDim(ax=2), # ax=2 is 'y'\n            {'x': 10},\n            [], [], ['x'],\n            lambda da: da.mean(dim='y').data\n        ),\n        # Case 5: AddAxis - Add a new dimension\n        (\n            AddAxis(ax=1), # Add new dim at axis 1\n            {'channel': 1, 'x': 10, 'y': 5},\n            ['channel'], [], ['x', 'y'],\n            lambda da: np.expand_dims(da.data, axis=0)\n        ),\n    ]\n)\ndef test_predict_on_array_all_models(\n    map_dataset_fixture, model, output_tensor_dim, new_dim, core_dim, resample_dim, manual_transform\n):\n    \"\"\"\n    Tests reassembly, averaging, and coordinate assignment using a variety of models.\n    \"\"\"\n    dataset = map_dataset_fixture\n    bgen = dataset.X_generator\n    resample_factor = _get_resample_factor(bgen, output_tensor_dim, resample_dim)\n\n    # --- Run the function under test ---\n    result_da = predict_on_array(\n        dataset=dataset, model=model, output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim, core_dim=core_dim, resample_dim=resample_dim, batch_size=4\n    )\n\n    # --- Manually calculate the expected result ---\n    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, core_dim, resample_dim)\n    expected_sum = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))\n    expected_count = xr.full_like(expected_sum, 0, dtype=int)\n\n    for i in range(len(dataset)):\n        batch_da = bgen[i]\n        old_indexer = bgen._batch_selectors.selectors[i][0]\n        new_indexer = {}\n        for key in old_indexer:\n            if key in resample_dim:\n                new_indexer[key] = slice(int(old_indexer[key].start * resample_factor.get(key, 1)), int(old_indexer[key].stop * resample_factor.get(key, 1)))\n            elif key in core_dim:\n                new_indexer[key] = old_indexer[key]\n\n        model_output_on_batch = manual_transform(batch_da)\n        print(f\"Batch {i}: {new_indexer} -> {model_output_on_batch.shape}\")\n        print(f\"Expected sum shape: {expected_sum.loc[new_indexer].shape}\")\n        expected_sum.loc[new_indexer] += model_output_on_batch\n        expected_count.loc[new_indexer] += 1\n        \n    expected_avg_data = expected_sum.data / expected_count.data\n    \n    # --- Assert correctness ---\n    np.testing.assert_allclose(result_da.values, expected_avg_data, equal_nan=True)\n\n!pytest -v test_predict_on_array.py","type":"content","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":7}]}