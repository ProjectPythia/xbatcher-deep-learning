{"version":"1","records":[{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers a workflow for using Xarray and xbatcher for deep learning applications. Specifically, it demonstrates a reusable workflow for recreating an xarray dataset from a deep learning model’s output, which can be used for further analysis or visualization.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"content":"This cookbook will be useful for data scientists and machine learning practitioners who want to leverage the power of xarray and xbatcher for their deep learning workflows. By the end of this cookbook, you will have gained skills in loading and processing Xarray datasets into a format suitable for deep learning using xbatcher and furthermore, you will learn how to recreate an Xarray dataset from the output of a deep learning model.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"content":"Keenan Ganz, \n\nNabin Kalauni","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections - “xbatcher Fundamentals” and “Example Workflow”. The first section covers the foundational concepts and tools needed to work with xbatcher and xarray, while the second section provides a practical example of how to use these tools in a complete end-to-end workflow.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"type":"lvl3","url":"/#xbatcher-fundamentals","position":10},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"content":"The foundational content includes an overview of xbatcher, its key features, and how it integrates with xarray for efficient data handling in deep learning workflows. The first chapter covers using xbatcher to create batches of data from an xarray dataset whereas the second chapter focuses on recreating an xarray dataset from the output of a deep learning model.","type":"content","url":"/#xbatcher-fundamentals","position":11},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"type":"lvl3","url":"/#example-workflow","position":12},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"content":"Example workflow includes using xbatcher to create batches of data from an xarray dataset (ASTER Global Digital Elevation model), training an Autoencoder on this data, and then using xbatcher again to reassemble the model’s output into a new xarray dataset.","type":"content","url":"/#example-workflow","position":13},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/xbatcher-deep-learning repository: git clone https://github.com/ProjectPythia/xbatcher-deep-learning.git\n\nMove into the xbatcher-deep-learning directorycd xbatcher-deep-learning\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder"},"type":"lvl1","url":"/notebooks/autoencoder","position":0},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder"},"content":"\n\n","type":"content","url":"/notebooks/autoencoder","position":1},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/autoencoder#imports","position":2},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Imports"},"content":"\n\nimport os\n\n# DL stuff\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\ntorch.set_default_dtype(torch.float64)\n\n# Geospatial stuff\nimport xarray as xr\nimport xbatcher\nimport rioxarray\nimport xbatcher\nfrom xbatcher.loaders.torch import MapDataset\n\n# Etc\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm.autonotebook import tqdm\n\n","type":"content","url":"/notebooks/autoencoder#imports","position":3},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Get data"},"type":"lvl2","url":"/notebooks/autoencoder#get-data","position":4},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Get data"},"content":"\n\nWe will start by pulling a segment of NASADEM for Washington’s Olympic peninsula.\n\n# Rasterio adds a blank edge. Trim these out.\ndem = rioxarray.open_rasterio(\"../ASTGTMV003_N47W124_dem.tif\")\ndem = dem.isel(y=slice(0, -1), x=slice(0, -1))\ndem = (dem - dem.min()) / (dem.max() - dem.min())\ndem\n\ndem.isel(band=0).plot.imshow(cmap=\"terrain\")\n\n","type":"content","url":"/notebooks/autoencoder#get-data","position":5},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Generate training examples"},"type":"lvl2","url":"/notebooks/autoencoder#generate-training-examples","position":6},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Generate training examples"},"content":"Here, we use xbatcher to window patches of terrain in the same location.\n\nbgen_x = xbatcher.BatchGenerator(\n    dem,\n    input_dims=dict(x=32, y=32),\n    input_overlap=dict(x=16, y=16)\n)\n\nds = MapDataset(\n    X_generator=bgen_x,)\n\nloader = torch.utils.data.DataLoader(ds, batch_size=16, shuffle=True)\n\nX = next(iter(loader))\n\nprint(\"Input tensor shape:\", X.shape)\n\n","type":"content","url":"/notebooks/autoencoder#generate-training-examples","position":7},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model setup"},"type":"lvl2","url":"/notebooks/autoencoder#model-setup","position":8},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model setup"},"content":"\n\nimport autoencoder\nfrom importlib import reload\nreload(autoencoder)\n\nm = autoencoder.Autoencoder(base_channel_size=32, latent_dim=64, num_input_channels=1, width=32, height=32)\nopt = m._configure_optimizers()\n\nout = m(X)\nprint(out.shape)\n\n","type":"content","url":"/notebooks/autoencoder#model-setup","position":9},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model training"},"type":"lvl2","url":"/notebooks/autoencoder#model-training","position":10},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model training"},"content":"We aren’t using pytorch-lightning here to keep the notebook environment lean. For your project, we highly recommend using a framework to abstract away much of the boilerplate code below.\n\ndef train_one_epoch(epoch_index):\n    last_loss = 0.\n    running_loss = 0.\n    \n    for i, batch in enumerate(tqdm(loader)):\n        # Zero your gradients for every batch!\n        opt.zero_grad()\n\n        # Make predictions for this batch\n        outputs = m(batch)\n\n        # Compute the loss and its gradients\n        loss = m._get_reconstruction_loss(batch, outputs)\n        loss.backward()\n        running_loss += loss.item()\n\n        # Adjust learning weights\n        opt.step()\n\n    return running_loss / len(loader)\n\nn_epochs = 5\nfor i_epoch in range(n_epochs):\n    loss = train_one_epoch(i_epoch)\n    print(f\"Epoch {i_epoch+1:>3}: {loss:.3e}\")\n\nDanger\n\nThis model is certainly overfitted. For brevity we have omitted a validation dataset, which is essential for building models that generalize well on unseen data.\n\nm.eval()\nn_examples = 4\ninputs = next(iter(loader))\noutputs = m(inputs)\n\ninputs = inputs.detach().cpu().numpy()\noutputs = outputs.detach().cpu().numpy()\n\nfig, axes = plt.subplots(n_examples, 2)\n\nfor i_row in range(n_examples):\n    axes[i_row, 0].imshow(inputs[i_row, 0, ...])\n    axes[i_row, 1].imshow(outputs[i_row, 0, ...])\n\nfor a in axes.flat:\n    a.set_xticks([])\n    a.set_yticks([])\n\naxes[0, 0].set_title(\"Original patch\")\naxes[0, 1].set_title(\"Reconstruction\")\n\nfig.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/autoencoder#model-training","position":11},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 1: Getting the full array back"},"type":"lvl2","url":"/notebooks/autoencoder#reconstruction-1-getting-the-full-array-back","position":12},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 1: Getting the full array back"},"content":"Suppose we would like to evaluate how the autoencoder does on reconstructing the entire terrain patch by combining outputs across all input patches. To do so we can use the predict_on_array function described in the previous notebook. Our model outputs tensors with shape (band=1, x=32, y=32). We need to specify each of these axes in the call to predict_on_array. channel does not change size and is not used by the BatchGenerator, so it goes in core_dim. Both x and y are used by the BatchGenerator, so although they do not change size they still go in resample_dim. That accounts for all tensor axes, so we can leave the new_dim argument as an empty list.\n\nimport functions\nreload(functions)\n\ndem_reconst = functions.predict_on_array(\n    dataset=ds,\n    model=m,\n    output_tensor_dim=dict(band=1, y=32, x=32),\n    new_dim=[],\n    core_dim=[\"band\"],\n    resample_dim=[\"x\", \"y\"]\n)\n\ndem_reconst.isel(band=0).plot.imshow(cmap=\"terrain\")\n\nThat certainly looks like the original DEM. Let’s try plotting the error in the reconstruction.\n\nerr = (dem_reconst - dem)\nerr.isel(band=0).plot.imshow()\nplt.show()\n\nerr.plot.hist()\nplt.show()\n\nNot bad!\n\n","type":"content","url":"/notebooks/autoencoder#reconstruction-1-getting-the-full-array-back","position":13},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 2: Getting the latent dimension"},"type":"lvl2","url":"/notebooks/autoencoder#reconstruction-2-getting-the-latent-dimension","position":14},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 2: Getting the latent dimension"},"content":"A common application of autoencoders is to use the latent dimension for some application. Let’s turn our autoencoder’s predictions into a data cube. To do so we will modify the batch generator to not have overlapping windows. We also have to slightly clip the size of the input DEM. This is because we are effectively downscaling the spatial axes by a factor of 32. Since 3600 / 32 is not an integer, predict_on_array will not know how to rescale the array size. So, we have to clip the DEM to the nearest integer multiple of 32. In this case the nearest multiple is 3584, which we achieve by clipping 8 pixels from each side.\n\nbgen_no_overlap = xbatcher.BatchGenerator(\n    dem.isel(x=slice(8, -8), y=slice(8, -8)),\n    input_dims=dict(x=32, y=32),\n    input_overlap=dict(x=0, y=0)\n)\n\nds_no_overlap = MapDataset(\n    X_generator=bgen_no_overlap\n)\n\nloader = torch.utils.data.DataLoader(ds_no_overlap, batch_size=16, shuffle=True)\n\nex_input = next(iter(loader))\n\n# Same as before\nprint(\"Input shape:\", ex_input.shape)\n\nNext we will write a function that the calls the encoder arm of the autoencoder and adds a fake x and y dimension.\n\ndef infer_with_encoder(x):\n    return m.encoder(x)[:, None, None, :]\n\nex_output = infer_with_encoder(ex_input)\nprint(\"Output shape:\", ex_output.shape)\n\nNow we combine the outputs together into a new data cube.\n\nlatent_dim_cube = functions.predict_on_array(\n    dataset=ds_no_overlap,\n    model=infer_with_encoder,\n    output_tensor_dim=dict(y=1, x=1, channel=64),\n    new_dim=[\"channel\"],\n    core_dim=[],\n    resample_dim=[\"x\", \"y\"]\n)\n\nlatent_dim_cube\n\nNote that despite substantially re-arranging the input DataArray, we have retained the coordinate information at a resampled resolution.\n\nIf we simply sum the output over the channel dimension, we see that the encoder clearly distinguishes between upland and lowland areas.\n\nlatent_dim_cube.sum(dim=\"channel\").plot.imshow()\n\nAs a final demonstration of this workflow, let’s compute the cosine similarity of each of the below pixels with the latent encoding of \n\nMt. Olympus.\n\nolympus = dict(x=-123.7066, y=47.7998)\nolympus_latent = latent_dim_cube.sel(**olympus, method=\"nearest\")\nolympus_latent\n\nfrom numpy.linalg import norm\n\ndef numpy_cosine_similarity(x, y):\n    return np.dot(x, y)/(norm(x)*norm(y))\n\nolympus_similarity = xr.apply_ufunc(\n    numpy_cosine_similarity,\n    latent_dim_cube,\n    input_core_dims = [[\"channel\"]],\n    output_core_dims = [[]],\n    vectorize=True,\n    kwargs=dict(y=olympus_latent.data)\n)\n\nolympus_similarity.plot.imshow()\nplt.scatter(olympus[\"x\"], olympus[\"y\"], marker=\"*\", c=\"purple\", edgecolor=\"black\", s=200)\nplt.show()\n\nSimilarly, we can identify foothills with similar topography to Grisdale, WA.\n\ngrisdale = dict(y=47.356625678465925, x=-123.61183314426664)\ngrisdale_latent = latent_dim_cube.sel(**grisdale, method=\"nearest\")\n\ngrisdale_similarity = xr.apply_ufunc(\n    numpy_cosine_similarity,\n    latent_dim_cube,\n    input_core_dims = [[\"channel\"]],\n    output_core_dims = [[]],\n    vectorize=True,\n    kwargs=dict(y=grisdale_latent.data)\n)\n\ngrisdale_similarity.plot.imshow()\nplt.scatter(grisdale[\"x\"], grisdale[\"y\"], marker=\"*\", c=\"purple\", edgecolor=\"black\", s=200)\nplt.show()\n\nThis result is admittedly very similar to if we had just selected elevation bands :)\n\n\n\n","type":"content","url":"/notebooks/autoencoder#reconstruction-2-getting-the-latent-dimension","position":15},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/autoencoder#summary","position":16},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Summary"},"content":"Our goal with this notebook has been to show how xbatcher supports linking xarray objects with deep learning models, and with converting model output back into labeled xarray objects. We have demonstrated two examples of reconstructing model output, both when tensor shape changes and when it does not.\n\nIf you encounter any issues, please open an issue on the GitHub repository for this cookbook. Other feedback is welcome!","type":"content","url":"/notebooks/autoencoder#summary","position":17},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Infer model on array"},"type":"lvl1","url":"/notebooks/inference-testing","position":0},{"hierarchy":{"lvl1":"Infer model on array"},"content":"\n\n","type":"content","url":"/notebooks/inference-testing","position":1},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/inference-testing#imports","position":2},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"content":"\n\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, predict_on_array\n\n","type":"content","url":"/notebooks/inference-testing#imports","position":3},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-array-size-function","position":4},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"content":"\n\n%%writefile test_get_array_size.py\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, _get_resample_factor\n\n%%writefile -a test_get_array_size.py\n\n@pytest.fixture\ndef bgen_fixture() -> xbatcher.BatchGenerator:\n    data = xr.DataArray(\n        data=np.random.rand(100, 100, 10),\n        dims=(\"x\", \"y\", \"t\"),\n        coords={\n            \"x\": np.arange(100),\n            \"y\": np.arange(100),\n            \"t\": np.arange(10),\n        }\n    )\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=10),\n        input_overlap=dict(x=5, y=5),\n    )\n    return bgen\n\n@pytest.mark.parametrize(\n    \"case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output\",\n    [\n        (\n            \"Resampling only: Downsample x, Upsample y\",\n            {'x': 5, 'y': 20},  \n            [],\n            [],\n            ['x', 'y'],\n            {'x': 50, 'y': 200} \n        ),\n        (\n            \"New dimensions only: Add a 'channel' dimension\",\n            {'channel': 3},\n            ['channel'],\n            [],\n            [],\n            {'channel': 3}\n        ),\n        (\n            \"Mixed: Resample x, add new channel dimension and keep t as core\",\n            {'x': 30, 'channel': 12, 't': 10}, \n            ['channel'],\n            ['t'],\n            ['x'],\n            {'x': 300, 'channel': 12, 't': 10} \n        ),\n        (\n            \"Identity resampling (ratio=1)\",\n            {'x': 10, 'y': 10},\n            [],\n            [],\n            ['x', 'y'],\n            {'x': 100, 'y': 100} \n        ),\n        (\n            \"Core dims only: 't' is a core dim\",\n            {'t': 10},\n            [], \n            ['t'], \n            [],\n            {'t': 10}\n        ),\n    ]\n)\ndef test_get_output_array_size_scenarios(\n    bgen_fixture,  # The fixture is passed as an argument\n    case_description,\n    output_tensor_dim,\n    new_dim,\n    core_dim,\n    resample_dim,\n    expected_output\n):\n    \"\"\"\n    Tests various valid scenarios for calculating the output array size.\n    The `case_description` parameter is not used in the code but helps make\n    test results more readable.\n    \"\"\"\n    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture\n    result = _get_output_array_size(\n        bgen=bgen_fixture,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        core_dim=core_dim,\n        resample_dim=resample_dim\n    )\n    \n    assert result == expected_output, f\"Failed on case: {case_description}\"\n\n%%writefile -a test_get_array_size.py\n\ndef test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a core_dim size doesn't match the source.\"\"\"\n    with pytest.raises(ValueError, match=\"does not equal the source data array size\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'t': 99}, new_dim=[], core_dim=['t'], resample_dim=[]\n        )\n\ndef test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a dimension is not specified in any category.\"\"\"\n    with pytest.raises(ValueError, match=\"must be specified in one of\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'x': 10}, new_dim=[], core_dim=[], resample_dim=[]\n        )\n\ndef test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):\n    \"\"\"Tests AssertionError when the resample ratio is not an integer or its inverse.\"\"\"\n    with pytest.raises(AssertionError, match=\"must be an integer or its inverse\"):\n        # 15 / 10 = 1.5, which is not a valid ratio\n        _get_resample_factor(bgen_fixture, output_tensor_dim={'x': 15}, resample_dim=['x'])\n\n!pytest -v test_get_array_size.py\n\n","type":"content","url":"/notebooks/inference-testing#testing-the-array-size-function","position":5},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":6},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"content":"\n\n%%writefile test_predict_on_array.py\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, _resample_coordinate\nfrom functions import predict_on_array, _get_resample_factor\nfrom dummy_models import Identity, MeanAlongDim, SubsetAlongAxis, ExpandAlongAxis, AddAxis\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import *\nfrom dummy_models import *\n\ninput_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)\ninput_tensor[0,0,:]\n\nmodel = ExpandAlongAxis(1, 2)\nmodel(input_tensor).shape\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.fixture\ndef map_dataset_fixture() -> MapDataset:\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10).astype(np.float32),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20, dtype=float), \"y\": np.arange(10, dtype=float)},\n    )\n    bgen = xbatcher.BatchGenerator(data, input_dims=dict(x=10, y=5), input_overlap=dict(x=2, y=2))\n    return MapDataset(bgen)\n\n\ndata = xr.DataArray(\n    data=np.arange(20 * 10).reshape(20, 10),\n    dims=(\"x\", \"y\"),\n    coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n).astype(float)\n\nbgen = xbatcher.BatchGenerator(\n    data,\n    input_dims=dict(x=10, y=5),\n    input_overlap=dict(x=2, y=2)\n)\n\nds = MapDataset(bgen)\n\ndata\n\nds[1]\n\noutput_tensor_dim = {'x': 20, 'y': 5}\nresample_dim = ['x', 'y']\ncore_dim = []\nnew_dim = []\n\nds[0].shape\n\nmodel(ds[0]).shape\n\nimport functions\nfrom importlib import reload\nreload(functions)\nresult = functions.predict_on_array(\n    ds,\n    model,\n    output_tensor_dim=output_tensor_dim,\n    new_dim=new_dim,\n    core_dim=core_dim,\n    resample_dim=resample_dim,\n    batch_size=4\n)\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\"factor, mode, expected\", [\n    (2.0, \"edges\", np.arange(0, 10, 0.5)),\n    (0.5, \"edges\", np.arange(0, 10, 2.0)),\n])\ndef test_resample_coordinate(factor, mode, expected):\n    coord = xr.DataArray(np.arange(10, dtype=float), dims=\"x\")\n    resampled = _resample_coordinate(coord, factor, mode)\n    np.testing.assert_allclose(resampled, expected)\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\n    \"model, output_tensor_dim, new_dim, core_dim, resample_dim, manual_transform\",\n    [\n        # Case 1: Identity - No change\n        (\n            Identity(),\n            {'x': 10, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.data\n        ),\n        # Case 2: ExpandAlongAxis - Upsampling\n        (\n            ExpandAlongAxis(ax=1, n_repeats=2), # ax=1 is 'x'\n            {'x': 20, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.data.repeat(2, axis=0) # axis=0 in the 2D numpy array\n        ),\n        # Case 3: SubsetAlongAxis - Coarsening\n        (\n            SubsetAlongAxis(ax=1, n=5), # ax=1 is 'x'\n            {'x': 5, 'y': 5},\n            [], [], ['x', 'y'],\n            lambda da: da.isel(x=slice(0, 5)).data\n        ),\n        # Case 4: MeanAlongDim - Dimension reduction\n        (\n            MeanAlongDim(ax=2), # ax=2 is 'y'\n            {'x': 10},\n            [], [], ['x'],\n            lambda da: da.mean(dim='y').data\n        ),\n        # Case 5: AddAxis - Add a new dimension\n        (\n            AddAxis(ax=1), # Add new dim at axis 1\n            {'channel': 1, 'x': 10, 'y': 5},\n            ['channel'], [], ['x', 'y'],\n            lambda da: np.expand_dims(da.data, axis=0)\n        ),\n    ]\n)\ndef test_predict_on_array_all_models(\n    map_dataset_fixture, model, output_tensor_dim, new_dim, core_dim, resample_dim, manual_transform\n):\n    \"\"\"\n    Tests reassembly, averaging, and coordinate assignment using a variety of models.\n    \"\"\"\n    dataset = map_dataset_fixture\n    bgen = dataset.X_generator\n    resample_factor = _get_resample_factor(bgen, output_tensor_dim, resample_dim)\n\n    # --- Run the function under test ---\n    result_da = predict_on_array(\n        dataset=dataset, model=model, output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim, core_dim=core_dim, resample_dim=resample_dim, batch_size=4\n    )\n\n    # --- Manually calculate the expected result ---\n    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, core_dim, resample_dim)\n    expected_sum = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))\n    expected_count = xr.full_like(expected_sum, 0, dtype=int)\n\n    for i in range(len(dataset)):\n        batch_da = bgen[i]\n        old_indexer = bgen._batch_selectors.selectors[i][0]\n        new_indexer = {}\n        for key in old_indexer:\n            if key in resample_dim:\n                new_indexer[key] = slice(int(old_indexer[key].start * resample_factor.get(key, 1)), int(old_indexer[key].stop * resample_factor.get(key, 1)))\n            elif key in core_dim:\n                new_indexer[key] = old_indexer[key]\n\n        model_output_on_batch = manual_transform(batch_da)\n        print(f\"Batch {i}: {new_indexer} -> {model_output_on_batch.shape}\")\n        print(f\"Expected sum shape: {expected_sum.loc[new_indexer].shape}\")\n        expected_sum.loc[new_indexer] += model_output_on_batch\n        expected_count.loc[new_indexer] += 1\n        \n    expected_avg_data = expected_sum.data / expected_count.data\n    \n    # --- Assert correctness ---\n    np.testing.assert_allclose(result_da.values, expected_avg_data, equal_nan=True)\n\n!pytest -v test_predict_on_array.py","type":"content","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":7},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets"},"type":"lvl1","url":"/notebooks/xbatcher-dataloading","position":0},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets"},"content":"Working with large, multi-dimensional datasets, common in fields like climate science and oceanography, presents a significant challenge when preparing data for machine learning models. The xbatcher library is designed to simplify this crucial preprocessing step.\n\nxbatcher is a Python package that facilitates the generation of data batches from xarray objects for machine learning. It serves as a bridge between the labeled, multi-dimensional data structures of xarray and the tensor-based inputs required by deep learning frameworks such as PyTorch and TensorFlow.\n\nThis guide provides an introduction to the fundamentals of xbatcher. We will cover how to create a BatchGenerator, customize it for specific needs, and prepare the resulting data for integration with a PyTorch model.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading","position":1},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#imports","position":2},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nfrom xbatcher.loaders.torch import MapDataset, IterableDataset\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#imports","position":3},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Creating a Sample Dataset"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#creating-a-sample-dataset","position":4},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Creating a Sample Dataset"},"content":"To begin, we will create a sample xarray.Dataset. This allows us to focus on the mechanics of xbatcher without the overhead of a specific real-world dataset. This sample can be replaced by any xarray.Dataset loaded from a file (e.g., NetCDF, Zarr).\n\nds = xr.Dataset(\n    {\n        \"temperature\": ((\"x\", \"y\", \"time\"), np.random.rand(100, 100, 50)),\n        \"precipitation\": ((\"x\", \"y\", \"time\"), np.random.rand(100, 100, 50)),\n    },\n    coords={\n        \"x\": np.arange(100),\n        \"y\": np.arange(100),\n        \"time\": np.arange(50),\n    },\n)\nds\n\nThe dataset contains two variables, temperature and precipitation, and three dimensions: x, y, and time. We will now use xbatcher to generate batches from this dataset.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#creating-a-sample-dataset","position":5},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"The BatchGenerator"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#the-batchgenerator","position":6},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"The BatchGenerator"},"content":"The BatchGenerator is the core component of xbatcher. It is a Python generator that yields batches of data from an xarray object.\n\nbgen = xbatcher.BatchGenerator(ds, input_dims={\"x\": 10, \"y\": 10})\n\nThe BatchGenerator is initialized with the dataset and the input_dims parameter. input_dims specifies the size of the batches along each dimension. In this case, we are creating batches of size 10x10 along the x and y dimensions. The time dimension is not specified, so xbatcher will yield batches that include all time steps.\n\nLet’s inspect the first batch generated.\n\nfirst_batch = next(iter(bgen))\nfirst_batch\n\nThe first batch has dimensions x=10, y=10, and time=50, as expected. The BatchGenerator will yield 100 batches in total (10 batches in the x-direction * 10 batches in the y-direction).\n\nprint(f\"The BatchGenerator contains {len(bgen)} batches.\")\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#the-batchgenerator","position":7},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Overlapping Batches with input_overlap"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#overlapping-batches-with-input-overlap","position":8},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Overlapping Batches with input_overlap"},"content":"In many applications, it is useful to have overlapping batches to provide context from neighboring data points. The input_overlap parameter allows for this.\n\nbgen_overlap = xbatcher.BatchGenerator(\n    ds, \n    input_dims={\"x\": 10, \"y\": 10}, \n    input_overlap={\"x\": 2, \"y\": 2}\n)\nfirst_batch_overlap = next(iter(bgen_overlap))\nfirst_batch_overlap\n\nThe input_overlap parameter specifies the number of elements to overlap between consecutive batches. The size of the batches themselves does not change. Let’s verify this by inspecting the coordinates of the first two batches.\n\nprint(f\"Batch 1 y-coords: {bgen_overlap[0].y.values}, Batch 1 x-coords: {bgen_overlap[0].x.values}\")\nprint(f\"Batch 2 y-coords: {bgen_overlap[1].y.values}, Batch 2 x-coords: {bgen_overlap[1].x.values}\")\nprint(f\"Batch 3 y-coords: {bgen_overlap[2].y.values}, Batch 3 x-coords: {bgen_overlap[2].x.values}\")\nprint(f\"Batch 13 y-coords: {bgen_overlap[12].y.values}, Batch 13 x-coords: {bgen_overlap[12].x.values}\")\nprint(f\"Batch 14 y-coords: {bgen_overlap[13].y.values}, Batch 11 x-coords: {bgen_overlap[13].x.values}\")\n\nAs you can see, the second batch starts at y=8, which is an overlap of 2 elements with the first batch, which ends at y=9.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#overlapping-batches-with-input-overlap","position":9},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Integration with PyTorch"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#integration-with-pytorch","position":10},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl2":"Integration with PyTorch"},"content":"xbatcher provides MapDataset and IterableDataset to wrap the BatchGenerator for use with PyTorch.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#integration-with-pytorch","position":11},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl3":"MapDataset vs. IterableDataset","lvl2":"Integration with PyTorch"},"type":"lvl3","url":"/notebooks/xbatcher-dataloading#mapdataset-vs-iterabledataset","position":12},{"hierarchy":{"lvl1":"Dataloading from Xarray Datasets","lvl3":"MapDataset vs. IterableDataset","lvl2":"Integration with PyTorch"},"content":"MapDataset: Implements __getitem__ and __len__, allowing for random access to data samples. This is the most common type of dataset in PyTorch.\n\nIterableDataset: Implements __iter__, and is suitable for very large datasets that may not fit into memory, as it streams data.\n\nWe will use MapDataset for this example.\n\nbgen[0].temperature.shape\nbgen[0].precipitation.shape\n\ndef patch_to_tensor(patch):\n    temp_patch = torch.tensor(patch.temperature.data)\n    prcp_patch = torch.tensor(patch.precipitation.data)\n    stacked_patch = torch.stack((temp_patch, prcp_patch), dim=0)\n    patch = stacked_patch\n    patch = torch.nan_to_num(patch)\n    # patch = torch.unsqueeze(patch, 0)\n    patch = patch.float()\n    return patch\n\nmap_ds = MapDataset(bgen, transform=patch_to_tensor)\n\nThe MapDataset can then be used with a PyTorch DataLoader, which provides utilities for shuffling, batching, and multiprocessing.\n\ndataloader = torch.utils.data.DataLoader(map_ds, batch_size=4)\n\nInspecting a batch from the DataLoader reveals a batch of PyTorch tensors.\n\ntorch_batch = next(iter(dataloader))\ntorch_batch.shape\n\nThe DataLoader has stacked 4 of the xbatcher batches, creating a new batch dimension of size 4. The data is now ready for use in a PyTorch model.\n\nIn the next notebook, we will explore how to reconstruct an xarray.Dataset from a model’s output.","type":"content","url":"/notebooks/xbatcher-dataloading#mapdataset-vs-iterabledataset","position":13},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs"},"type":"lvl1","url":"/notebooks/xbatcher-reconstruction","position":0},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs"},"content":"This notebook addresses the process of reconstructing an xarray.DataArray from the output of a machine learning model. While the previous notebook focused on generating batches from xarray objects, this guide details the reverse process: assembling model outputs back into a coherent, labeled xarray object. This is a common requirement in scientific machine learning workflows, where the model output needs to be analyzed in its original spatial or temporal context.\n\nWe will examine a function that reassembles model outputs, including a detailed look at how an internal API of xbatcher can be used to map batch outputs back to their original coordinates.\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction","position":1},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#imports","position":2},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nfrom xbatcher.loaders.torch import MapDataset\nfrom typing import Literal\n\nfrom dummy_models import ExpandAlongAxis\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#imports","position":3},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Setup: Data, Batches, and a Dummy Model"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#setup-data-batches-and-a-dummy-model","position":4},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Setup: Data, Batches, and a Dummy Model"},"content":"We will begin by creating a sample xarray.DataArray and a BatchGenerator. We will also instantiate a dummy model that transforms the data, simulating a common machine learning scenario where the output dimensions differ from the input dimensions (e.g., super-resolution).\n\nda = xr.DataArray(\n    data=np.random.rand(50, 40).astype(np.float32),\n    dims=(\"x\", \"y\"),\n    coords={\"x\": np.arange(50), \"y\": np.arange(40)},\n)\nda\n\nNext, we create the BatchGenerator.\n\nbgen = xbatcher.BatchGenerator(da, input_dims={\"x\": 10, \"y\": 10})\n\nFor the model, we will use ExpandAlongAxis from dummy_models.py. This model upsamples the input along a specified axis, changing the dimensions of the data.\n\n# The model will expand the 'x' dimension by a factor of 2\nmodel = ExpandAlongAxis(ax=1, n_repeats=2)\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#setup-data-batches-and-a-dummy-model","position":5},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"The predict_on_array Function"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#the-predict-on-array-function","position":6},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"The predict_on_array Function"},"content":"The predict_on_array function (from functions.py) is designed to take batches from a BatchGenerator, pass them through a model, and reassemble the outputs. The following sections will break down this function and its helpers.\n\ndef _get_resample_factor(\n    bgen: xbatcher.BatchGenerator,\n    output_tensor_dim: dict[str, int],\n    resample_dim: list[str]\n):\n    resample_factor = {}\n    for dim in resample_dim:\n        r = output_tensor_dim[dim] / bgen.input_dims[dim]\n        is_int = (r == int(r))\n        is_inv_int = (1/r == int(1/r)) if r != 0 else False\n        assert is_int or is_inv_int, f\"Resample ratio for dim '{dim}' must be an integer or its inverse.\"\n        resample_factor[dim] = r\n\n    return resample_factor\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#the-predict-on-array-function","position":7},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_resample_factor","lvl2":"The predict_on_array Function"},"type":"lvl3","url":"/notebooks/xbatcher-reconstruction#id-get-resample-factor","position":8},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_resample_factor","lvl2":"The predict_on_array Function"},"content":"This helper function calculates the resampling factor for each dimension. For example, if input batches have x=10 and the model outputs tensors with x=20, the resampling factor for x is 2. This is used to determine the dimensions of the final reconstructed array.\n\ndef _get_output_array_size(\n    bgen: xbatcher.BatchGenerator,\n    output_tensor_dim: dict[str, int],\n    new_dim: list[str],\n    core_dim: list[str],\n    resample_dim: list[str]\n):\n    resample_factor = _get_resample_factor(bgen, output_tensor_dim, resample_dim)\n    output_size = {}\n    for key, size in output_tensor_dim.items():\n        if key in new_dim:\n            output_size[key] = output_tensor_dim[key]\n        elif key in core_dim:\n            if output_tensor_dim[key] != bgen.ds.sizes[key]:\n                raise ValueError(\n                    f\"Axis {key} is a core dim, but the tensor size\"\n                    f\"({output_tensor_dim[key]}) does not equal the \"\n                    f\"source data array size ({bgen.ds.sizes[key]}).\"\n                )\n            output_size[key] = bgen.ds.sizes[key]\n        elif key in resample_dim:\n            temp_output_size = bgen.ds.sizes[key] * resample_factor[key]\n            assert temp_output_size.is_integer(), f\"Resampling for dim '{key}' results in non-integer size.\"\n            output_size[key] = int(temp_output_size)\n        else:\n            raise ValueError(f\"Axis {key} must be specified in one of new_dim, core_dim, or resample_dim\") \n    return output_size\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#id-get-resample-factor","position":9},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_output_array_size","lvl2":"The predict_on_array Function"},"type":"lvl3","url":"/notebooks/xbatcher-reconstruction#id-get-output-array-size","position":10},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_output_array_size","lvl2":"The predict_on_array Function"},"content":"This function determines the final size of the reconstructed array. It uses the resampling factor and also considers new_dim (dimensions that are new in the output) and core_dim (dimensions that are not batched over and remain unchanged).\n\ndef _resample_coordinate(\n    coord: xr.DataArray,\n    factor: float,\n    mode: Literal[\"centers\", \"edges\"]=\"edges\"\n) -> np.ndarray:\n    assert len(coord.shape) == 1 and coord.shape[0] > 1\n    assert (coord.shape[0] * factor).is_integer()\n    old_step = (coord.data[1] - coord.data[0])\n    offset = 0 if mode == \"edges\" else old_step / 2\n    new_step = old_step / factor\n    coord = coord - offset\n    new_coord_end = coord.max().item() + old_step\n    return np.arange(coord.min().item(), new_coord_end, step=new_step) + offset\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#id-get-output-array-size","position":11},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_resample_coordinate","lvl2":"The predict_on_array Function"},"type":"lvl3","url":"/notebooks/xbatcher-reconstruction#id-resample-coordinate","position":12},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_resample_coordinate","lvl2":"The predict_on_array Function"},"content":"If the size of a dimension is changed, its coordinates must also be updated. This function handles the resampling of coordinates.\n\ndef _get_output_array_coordinates(\n    src_da: xr.DataArray,\n    output_array_dim: list[str],\n    resample_factor: dict[str, int],\n    resample_mode: Literal[\"centers\", \"edges\"]=\"edges\"\n) -> dict[str, np.ndarray]:\n    output_coords = {}\n    for dim in output_array_dim:\n        if dim in src_da.coords and dim in resample_factor:\n            output_coords[dim] = _resample_coordinate(src_da[dim], resample_factor[dim], resample_mode)\n        elif dim in src_da.coords:\n            output_coords[dim] = src_da[dim].copy(deep=True).data\n        else:\n            continue\n    return output_coords\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#id-resample-coordinate","position":13},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_output_array_coordinates","lvl2":"The predict_on_array Function"},"type":"lvl3","url":"/notebooks/xbatcher-reconstruction#id-get-output-array-coordinates","position":14},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"_get_output_array_coordinates","lvl2":"The predict_on_array Function"},"content":"This function generates a dictionary of the new coordinates for the output array.\n\ndef predict_on_array(\n    dataset: MapDataset,\n    model: torch.nn.Module,\n    output_tensor_dim: dict[str, int],\n    new_dim: list[str],\n    core_dim: list[str],\n    resample_dim: list[str],\n    resample_mode: Literal[\"centers\", \"edges\"]=\"edges\",\n    batch_size: int=16\n) -> xr.DataArray:\n    s_new = set(new_dim)\n    s_core = set(core_dim)\n    s_resample = set(resample_dim)\n\n    if s_new & s_core or s_new & s_resample or s_core & s_resample:\n        raise ValueError(\"new_dim, core_dim, and resample_dim must be disjoint sets.\")\n\n    bgen = dataset.X_generator\n\n    resample_factor = _get_resample_factor(\n        bgen,\n        output_tensor_dim, \n        resample_dim\n    )\n    \n    output_size = _get_output_array_size(\n        bgen,\n        output_tensor_dim,\n        new_dim,\n        core_dim,\n        resample_dim\n    )\n            \n    output_da = xr.DataArray(\n        data=np.zeros(tuple(output_size.values())),\n        dims=tuple(output_size.keys()),\n    )\n    output_n = xr.full_like(output_da, 0)\n    \n    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n\n    for i, batch in enumerate(loader):\n        input_tensor = batch[0] if isinstance(batch, (list, tuple)) else batch\n        out_batch = model(input_tensor).detach().numpy()\n\n        for ib in range(out_batch.shape[0]):\n            global_index = (i * batch_size) + ib\n            old_indexer = bgen._batch_selectors.selectors[global_index][0]\n            new_indexer = {}\n            for key in old_indexer:\n                if key in resample_dim:\n                    new_indexer[key] = slice(\n                        int(old_indexer[key].start * resample_factor[key]),\n                        int(old_indexer[key].stop * resample_factor[key])\n                    )\n\n            output_da.loc[new_indexer] += out_batch[ib, ...]\n            output_n.loc[new_indexer] += 1\n\n    output_da = output_da / output_n\n\n    output_da = output_da.assign_coords(\n        _get_output_array_coordinates(\n            dataset.X_generator.ds, \n            list(output_tensor_dim.keys()), \n            resample_factor, \n            resample_mode\n        )\n    )\n\n    return output_da\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#id-get-output-array-coordinates","position":15},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"predict_on_array Internals","lvl2":"The predict_on_array Function"},"type":"lvl3","url":"/notebooks/xbatcher-reconstruction#predict-on-array-internals","position":16},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl3":"predict_on_array Internals","lvl2":"The predict_on_array Function"},"content":"The key steps of this function are as follows:\n\nInitialization: An empty DataArray (output_da) is created with the final dimensions, along with a corresponding DataArray (output_n) to track the number of predictions for each element (for averaging in case of overlaps).\n\nIteration: The function iterates through the DataLoader.\n\nThe Internal API: The core of the reconstruction is bgen._batch_selectors.selectors[global_index]. This internal attribute of the BatchGenerator stores the slice objects for each batch, providing a map from the batch to the original DataArray’s coordinate space.\n\nDisclaimer: Accessing internal attributes such as _batch_selectors is not part of the public API and may change in future versions of xbatcher.\n\nRescaling and Placing: The resampling factor is used to scale the slices, and .loc is used to place the model’s output into the correct location in output_da.\n\nAveraging and Coordinates: Finally, the predictions are averaged (if there were overlaps) and the new coordinates are assigned.\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#predict-on-array-internals","position":17},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Reconstructing the Dataset"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#reconstructing-the-dataset","position":18},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Reconstructing the Dataset"},"content":"We will now use the predict_on_array function to reconstruct the dataset.\n\nmap_dataset = MapDataset(bgen)\nreconstructed_da = predict_on_array(\n    dataset=map_dataset,\n    model=model,\n    output_tensor_dim={\"x\": 20, \"y\": 10}, # The model doubles the x-dimension\n    new_dim=[],\n    core_dim=[],\n    resample_dim=[\"x\", \"y\"],\n    batch_size=4\n)\nreconstructed_da\n\nThe reconstructed DataArray has the upsampled x dimension. We can compare its shape to the original.\n\nprint(f\"Original shape: {da.shape}\")\nprint(f\"Reconstructed shape: {reconstructed_da.shape}\")\n\nThe reconstructed array has twice the number of elements in the x dimension, as expected. This concludes the demonstration of reconstructing an xarray.Dataset from model outputs using xbatcher.","type":"content","url":"/notebooks/xbatcher-reconstruction#reconstructing-the-dataset","position":19}]}