{"version":2,"kind":"Notebook","sha256":"6bbc48cf512f0a09654786745457af79ed39b263df10bd7e88f213656a365b8a","slug":"notebooks.inference-testing","location":"/notebooks/inference-testing.ipynb","dependencies":[],"frontmatter":{"title":"Infer model on array","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"cookbook-dev","language":"python"},"authors":[{"nameParsed":{"literal":"The Project Pythia Community","given":"The Project Pythia","family":"Community"},"name":"The Project Pythia Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/projectpythia/xbatcher-deep-learning","copyright":"2024","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/projectpythia/xbatcher-deep-learning/blob/main/notebooks/inference-testing.ipynb","exports":[{"format":"ipynb","filename":"inference-testing.ipynb","url":"/xbatcher-deep-learning/build/inference-testing-6eecc46a379422ed6e1e4a0d54f82565.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"thematicBreak","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UpVfMYCcZv"}],"key":"HGJtS2GbNo"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Imports","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pVudlxS5vz"}],"identifier":"imports","label":"Imports","html_id":"imports","implicit":true,"key":"AkmFuc5zaw"}],"key":"Rzxo4Gpqnp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, predict_on_array","key":"eR6LOL0Ypk"},{"type":"output","id":"pB-Ky8H64VdJ2JmOVBJH9","data":[],"key":"bzoQHMAHFM"}],"key":"Z2kAPxJOfG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Testing the array size function","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QzLlTH6ALR"}],"identifier":"testing-the-array-size-function","label":"Testing the array size function","html_id":"testing-the-array-size-function","implicit":true,"key":"nAgJQhI2fs"}],"key":"DaVAPpgko6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile test_get_array_size.py\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, _get_resample_factor","key":"blQbqx2uXh"},{"type":"output","id":"z4NFP6BwGCmVsDnD2KgNe","data":[{"output_type":"stream","name":"stdout","text":"Overwriting test_get_array_size.py\n"}],"key":"Q7Sa8oEtiN"}],"key":"QTfU0mIGQA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_get_array_size.py\n\n@pytest.fixture\ndef bgen_fixture() -> xbatcher.BatchGenerator:\n    data = xr.DataArray(\n        data=np.random.rand(100, 100, 10),\n        dims=(\"x\", \"y\", \"t\"),\n        coords={\n            \"x\": np.arange(100),\n            \"y\": np.arange(100),\n            \"t\": np.arange(10),\n        }\n    )\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=10),\n        input_overlap=dict(x=5, y=5),\n    )\n    return bgen\n\n@pytest.mark.parametrize(\n    \"case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output\",\n    [\n        (\n            \"Resampling only: Downsample x, Upsample y\",\n            {'x': 5, 'y': 20},  \n            [],\n            [],\n            ['x', 'y'],\n            {'x': 50, 'y': 200} \n        ),\n        (\n            \"New dimensions only: Add a 'channel' dimension\",\n            {'channel': 3},\n            ['channel'],\n            [],\n            [],\n            {'channel': 3}\n        ),\n        (\n            \"Mixed: Resample x, add new channel dimension and keep t as core\",\n            {'x': 30, 'channel': 12}, \n            ['channel'],\n            ['t'],\n            ['x'],\n            {'x': 300, 'channel': 12} \n        ),\n        (\n            \"Identity resampling (ratio=1)\",\n            {'x': 10, 'y': 10},\n            [],\n            [],\n            ['x', 'y'],\n            {'x': 100, 'y': 100} \n        ),\n        (\n            \"Core dims only: 't' is a core dim\",\n            {'t': 10},\n            [], \n            ['t'], \n            [],\n            {'t': 10}\n        ),\n    ]\n)\ndef test_get_output_array_size_scenarios(\n    bgen_fixture,  # The fixture is passed as an argument\n    case_description,\n    output_tensor_dim,\n    new_dim,\n    core_dim,\n    resample_dim,\n    expected_output\n):\n    \"\"\"\n    Tests various valid scenarios for calculating the output array size.\n    The `case_description` parameter is not used in the code but helps make\n    test results more readable.\n    \"\"\"\n    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture\n    result = _get_output_array_size(\n        bgen=bgen_fixture,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        core_dim=core_dim,\n        resample_dim=resample_dim\n    )\n    \n    assert result == expected_output, f\"Failed on case: {case_description}\"","key":"KHkmMcM6TQ"},{"type":"output","id":"hNOUX1fiZa74KDAH6Z50O","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_get_array_size.py\n"}],"key":"wtEdZllR3K"}],"key":"irSbGAtSVE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_get_array_size.py\n\ndef test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a core_dim size doesn't match the source.\"\"\"\n    with pytest.raises(ValueError, match=\"does not equal the source data array size\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'t': 99}, new_dim=[], core_dim=['t'], resample_dim=[]\n        )\n\ndef test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a dimension is not specified in any category.\"\"\"\n    with pytest.raises(ValueError, match=\"must be specified in one of\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'x': 10}, new_dim=[], core_dim=[], resample_dim=[]\n        )\n\ndef test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):\n    \"\"\"Tests AssertionError when the resample ratio is not an integer or its inverse.\"\"\"\n    with pytest.raises(AssertionError, match=\"must be an integer or its inverse\"):\n        # 15 / 10 = 1.5, which is not a valid ratio\n        _get_resample_factor(bgen_fixture, output_tensor_dim={'x': 15}, resample_dim=['x'])","key":"GtGxrgBM30"},{"type":"output","id":"o8LOlrqvHRKSdMmfF0vMR","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_get_array_size.py\n"}],"key":"jMpg8naT5d"}],"key":"beAobmWMNR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"!pytest -v test_get_array_size.py","key":"t7TMRvFssj"},{"type":"output","id":"ag3DZW8ipIusWt8K17Kxb","data":[{"output_type":"stream","name":"stdout","text":"\u001b[1m============================= test session starts ==============================\u001b[0m\r\nplatform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13\r\ncachedir: .pytest_cache\r\nrootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks\r\nplugins: anyio-4.10.0\r\n\u001b[1mcollecting ... \u001b[0m"},{"output_type":"stream","name":"stdout","text":"\u001b[1m\rcollecting 8 items                                                             \u001b[0m\u001b[1m\rcollected 8 items                                                              \u001b[0m\r\n\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Resampling only: Downsample x, Upsample y-output_tensor_dim0-new_dim0-core_dim0-resample_dim0-expected_output0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[New dimensions only: Add a 'channel' dimension-output_tensor_dim1-new_dim1-core_dim1-resample_dim1-expected_output1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Mixed: Resample x, add new channel dimension and keep t as core-output_tensor_dim2-new_dim2-core_dim2-resample_dim2-expected_output2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Identity resampling (ratio=1)-output_tensor_dim3-new_dim3-core_dim3-resample_dim3-expected_output3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Core dims only: 't' is a core dim-output_tensor_dim4-new_dim4-core_dim4-resample_dim4-expected_output4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_raises_error_on_mismatched_core_dim \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_raises_error_on_unspecified_dim \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\r\ntest_get_array_size.py::test_get_resample_factor_raises_error_on_invalid_ratio \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\r\n\r\n\u001b[32m============================== \u001b[32m\u001b[1m8 passed\u001b[0m\u001b[32m in 1.51s\u001b[0m\u001b[32m ===============================\u001b[0m\r\n"}],"key":"TnzDwvAUxL"}],"key":"NLMDwftduI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Testing the predict_on_array function","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GiDsLmjVtX"}],"identifier":"testing-the-predict-on-array-function","label":"Testing the predict_on_array function","html_id":"testing-the-predict-on-array-function","implicit":true,"key":"u5gbqv2Mxm"}],"key":"pbFBRXiFrB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile test_predict_on_array.py\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *","key":"xGRzE6bEZk"},{"type":"output","id":"TdlxPgEtIi7kSpg0N3ffp","data":[{"output_type":"stream","name":"stdout","text":"Overwriting test_predict_on_array.py\n"}],"key":"fOCMPAk4At"}],"key":"oZQ7a8kZPG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *","key":"SVO2zAj7Me"},{"type":"output","id":"ibfotUOe_qzAYxZGuAkh8","data":[],"key":"dIgDHhQnZu"}],"key":"OsaVrgJTJA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"input_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)\ninput_tensor[0,0,:]","key":"xxoFr3Kj7h"},{"type":"output","id":"bbHMxLRXRcI4D5w8xIXyw","data":[{"output_type":"execute_result","execution_count":8,"metadata":{},"data":{"text/plain":{"content":"tensor([0., 1., 2., 3., 4.])","content_type":"text/plain"}}}],"key":"KCG7Di3VmR"}],"key":"tqtbBjKaNx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model = MeanAlongDim(-1)\nmodel(input_tensor)","key":"Jsx2yRp41S"},{"type":"output","id":"LiKyOJoevc0fybdPNeOBF","data":[{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"tensor([[  2.,   7.,  12.,  17.,  22.],\n        [ 27.,  32.,  37.,  42.,  47.],\n        [ 52.,  57.,  62.,  67.,  72.],\n        [ 77.,  82.,  87.,  92.,  97.],\n        [102., 107., 112., 117., 122.]])","content_type":"text/plain"}}}],"key":"CBlTW6oGx0"}],"key":"PtLyGHjm2m"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_predict_on_array.py\n\n@pytest.fixture\ndef map_dataset_fixture() -> MapDataset:\n    \"\"\"\n    Creates a MapDataset with a predictable BatchGenerator for testing.\n    - Data is an xarray DataArray with dimensions x=20, y=10\n    - Values are a simple np.arange sequence for easy verification.\n    - Batches are size x=10, y=5 with overlap x=2, y=2\n    \"\"\"\n    # Using a smaller, more manageable dataset for testing\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )\n    return MapDataset(bgen)","key":"r3mIksx1AU"},{"type":"output","id":"7eOyvxp9t0Xwbbnx1Csyz","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_predict_on_array.py\n"}],"key":"cQoBitbL48"}],"key":"m1Z8vLVFyQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )","key":"wjqPUsOsjK"},{"type":"output","id":"_4EsFmrUXaF8QWzDOhdxR","data":[],"key":"e7tSKDPrU9"}],"key":"bRR8L0o3nV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\n    \"model, output_tensor_dim, new_dim, resample_dim, expected_transform\",\n    [\n        # Case 1: Resampling - Downsampling with a subset model\n        (\n            SubsetAlongAxis(ax=1, n=5), # Corresponds to 'x' dim in batch\n            {'x': 5, 'y': 5},\n            [],\n            ['x'],\n            lambda da: da.isel(x=slice(0, 5)) # Expected: take first 5 elements of original 'x'\n        ),\n        # Case 2: Dimension reduction with a mean model\n        (\n            MeanAlongDim(ax=2), # Corresponds to 'y' dim in batch\n            {'x': 10},\n            [],\n            ['x'],\n            lambda da: da.mean(dim='y') # Expected: mean along original 'y'\n        ),\n    ]\n)\ndef test_predict_on_array_reassembly(\n    map_dataset_fixture,\n    model,\n    output_tensor_dim,\n    new_dim,\n    resample_dim,\n    expected_transform\n):\n    \"\"\"\n    Tests that predict_on_array correctly reassembles batches from different models.\n    \"\"\"\n    # --- Run the function under test ---\n    # Using a small batch_size to ensure multiple iterations\n    predicted_da, predicted_n = predict_on_array(\n        dataset=map_dataset_fixture,\n        model=model,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        resample_dim=resample_dim,\n        batch_size=4 \n    )\n\n    # --- Manually calculate the expected result ---\n    bgen = map_dataset_fixture.generator\n    # 1. Create the expected output array structure\n    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, resample_dim)\n    expected_da = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))\n    expected_n = xr.full_like(expected_da, 0)\n\n    # 2. Manually iterate through batches and apply the same logic as the function\n    for i in range(len(map_dataset_fixture)):\n        batch_da = bgen[i]\n        \n        # Apply the same transformation the model would\n        transformed_batch = expected_transform(batch_da)\n        \n        # Get the rescaled indexer\n        old_indexer = bgen.batch_selectors[i]\n        new_indexer = {}\n        for key in old_indexer:\n            if key in resample_dim:\n                resample_ratio = output_tensor_dim[key] / bgen.input_dims[key]\n                new_indexer[key] = slice(\n                    int(old_indexer[key].start * resample_ratio),\n                    int(old_indexer[key].stop * resample_ratio)\n                )\n        \n        # Add the result to our manually calculated array\n        expected_da.loc[new_indexer] += transformed_batch.values\n        expected_n.loc[new_indexer] += 1\n\n    # --- Assert that the results are identical ---\n    # We test the raw summed output and the overlap counter array\n    xr.testing.assert_allclose(predicted_da, expected_da)\n    xr.testing.assert_allclose(predicted_n, expected_n)","key":"qbQLq3S3H2"},{"type":"output","id":"N51vPbZ9KwgHGCaTaWQUv","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_predict_on_array.py\n"}],"key":"R1vCL8HaOq"}],"key":"cEAo2LM2fY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"!pytest -v test_predict_on_array.py","key":"LOtjJ37JXd"},{"type":"output","id":"iHUkEUQb-caZhXd1VPZPD","data":[{"output_type":"stream","name":"stdout","text":"\u001b[1m============================= test session starts ==============================\u001b[0m\r\nplatform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13\r\ncachedir: .pytest_cache\r\nrootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks\r\nplugins: anyio-4.10.0\r\n\u001b[1mcollecting ... \u001b[0m"},{"output_type":"stream","name":"stdout","text":"\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollected 2 items                                                              \u001b[0m\r\n\r\ntest_predict_on_array.py::test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-<lambda>] "},{"output_type":"stream","name":"stdout","text":"\u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\r\ntest_predict_on_array.py::test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-<lambda>] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\r\n\r\n=================================== FAILURES ===================================\r\n\u001b[31m\u001b[1m_ test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-<lambda>] _\u001b[0m\r\n\r\nmap_dataset_fixture = <xbatcher.loaders.torch.MapDataset object at 0x7fbeb9544590>\r\nmodel = SubsetAlongAxis(), output_tensor_dim = {'x': 5, 'y': 5}, new_dim = []\r\nresample_dim = ['x'], expected_transform = <function <lambda> at 0x7fbeb9368860>\r\n\r\n    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\r\n        \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel, output_tensor_dim, new_dim, resample_dim, expected_transform\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\r\n        [\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 1: Resampling - Downsampling with a subset model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                SubsetAlongAxis(ax=\u001b[94m1\u001b[39;49;00m, n=\u001b[94m5\u001b[39;49;00m), \u001b[90m# Corresponds to 'x' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.isel(x=\u001b[96mslice\u001b[39;49;00m(\u001b[94m0\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) \u001b[90m# Expected: take first 5 elements of original 'x'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 2: Dimension reduction with a mean model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                MeanAlongDim(ax=\u001b[94m2\u001b[39;49;00m), \u001b[90m# Corresponds to 'y' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m10\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.mean(dim=\u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[90m# Expected: mean along original 'y'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n        ]\u001b[90m\u001b[39;49;00m\r\n    )\u001b[90m\u001b[39;49;00m\r\n    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_predict_on_array_reassembly\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\r\n        map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n        model,\u001b[90m\u001b[39;49;00m\r\n        output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n        new_dim,\u001b[90m\u001b[39;49;00m\r\n        resample_dim,\u001b[90m\u001b[39;49;00m\r\n        expected_transform\u001b[90m\u001b[39;49;00m\r\n    ):\u001b[90m\u001b[39;49;00m\r\n    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\r\n    \u001b[33m    Tests that predict_on_array correctly reassembles batches from different models.\u001b[39;49;00m\r\n    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# --- Run the function under test ---\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# Using a small batch_size to ensure multiple iterations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n>       predicted_da, predicted_n = predict_on_array(\u001b[90m\u001b[39;49;00m\r\n            dataset=map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n            model=model,\u001b[90m\u001b[39;49;00m\r\n            output_tensor_dim=output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n            new_dim=new_dim,\u001b[90m\u001b[39;49;00m\r\n            resample_dim=resample_dim,\u001b[90m\u001b[39;49;00m\r\n            batch_size=\u001b[94m4\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        )\u001b[90m\u001b[39;49;00m\r\n\u001b[1m\u001b[31mE       TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\u001b[0m\r\n\r\n\u001b[1m\u001b[31mtest_predict_on_array.py\u001b[0m:67: TypeError\r\n\u001b[31m\u001b[1m_ test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-<lambda>] _\u001b[0m\r\n\r\nmap_dataset_fixture = <xbatcher.loaders.torch.MapDataset object at 0x7fbeb948a490>\r\nmodel = MeanAlongDim(), output_tensor_dim = {'x': 10}, new_dim = []\r\nresample_dim = ['x'], expected_transform = <function <lambda> at 0x7fbeb9368e00>\r\n\r\n    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\r\n        \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel, output_tensor_dim, new_dim, resample_dim, expected_transform\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\r\n        [\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 1: Resampling - Downsampling with a subset model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                SubsetAlongAxis(ax=\u001b[94m1\u001b[39;49;00m, n=\u001b[94m5\u001b[39;49;00m), \u001b[90m# Corresponds to 'x' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.isel(x=\u001b[96mslice\u001b[39;49;00m(\u001b[94m0\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) \u001b[90m# Expected: take first 5 elements of original 'x'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 2: Dimension reduction with a mean model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                MeanAlongDim(ax=\u001b[94m2\u001b[39;49;00m), \u001b[90m# Corresponds to 'y' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m10\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.mean(dim=\u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[90m# Expected: mean along original 'y'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n        ]\u001b[90m\u001b[39;49;00m\r\n    )\u001b[90m\u001b[39;49;00m\r\n    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_predict_on_array_reassembly\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\r\n        map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n        model,\u001b[90m\u001b[39;49;00m\r\n        output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n        new_dim,\u001b[90m\u001b[39;49;00m\r\n        resample_dim,\u001b[90m\u001b[39;49;00m\r\n        expected_transform\u001b[90m\u001b[39;49;00m\r\n    ):\u001b[90m\u001b[39;49;00m\r\n    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\r\n    \u001b[33m    Tests that predict_on_array correctly reassembles batches from different models.\u001b[39;49;00m\r\n    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# --- Run the function under test ---\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# Using a small batch_size to ensure multiple iterations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n>       predicted_da, predicted_n = predict_on_array(\u001b[90m\u001b[39;49;00m\r\n            dataset=map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n            model=model,\u001b[90m\u001b[39;49;00m\r\n            output_tensor_dim=output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n            new_dim=new_dim,\u001b[90m\u001b[39;49;00m\r\n            resample_dim=resample_dim,\u001b[90m\u001b[39;49;00m\r\n            batch_size=\u001b[94m4\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        )\u001b[90m\u001b[39;49;00m\r\n\u001b[1m\u001b[31mE       TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\u001b[0m\r\n\r\n\u001b[1m\u001b[31mtest_predict_on_array.py\u001b[0m:67: TypeError\r\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\r\n\u001b[31mFAILED\u001b[0m test_predict_on_array.py::\u001b[1mtest_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-<lambda>]\u001b[0m - TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\r\n\u001b[31mFAILED\u001b[0m test_predict_on_array.py::\u001b[1mtest_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-<lambda>]\u001b[0m - TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\r\n\u001b[31m============================== \u001b[31m\u001b[1m2 failed\u001b[0m\u001b[31m in 1.57s\u001b[0m\u001b[31m ===============================\u001b[0m\r\n"}],"key":"zMYF02IufQ"}],"key":"cwnU5HNSVs"}],"key":"ECgMtaZzo6"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"How to Cite This Cookbook","url":"/notebooks/how-to-cite","group":"Preamble"}}},"domain":"http://localhost:3000"}