{"version":"1","records":[{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributor’s Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Motivation"},"content":"(Add a few sentences stating why this cookbook will be useful. What skills will you, “the chef”, gain once you have reached the end of the cookbook?)","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Authors"},"content":"First Author, \n\nSecond Author, etc. Acknowledge primary content authors here","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - “Foundations” and “Example Workflows.” Then, describe each section below.)","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":10},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":11},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":12},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":13},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"(Replace_with_your_title) Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace “cookbook-example” with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Infer model on array"},"type":"lvl1","url":"/notebooks/inference-testing","position":0},{"hierarchy":{"lvl1":"Infer model on array"},"content":"\n\n","type":"content","url":"/notebooks/inference-testing","position":1},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/inference-testing#imports","position":2},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Imports"},"content":"\n\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, predict_on_array\n\n","type":"content","url":"/notebooks/inference-testing#imports","position":3},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-array-size-function","position":4},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the array size function"},"content":"\n\n%%writefile test_get_array_size.py\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, _get_resample_factor\n\n%%writefile -a test_get_array_size.py\n\n@pytest.fixture\ndef bgen_fixture() -> xbatcher.BatchGenerator:\n    data = xr.DataArray(\n        data=np.random.rand(100, 100, 10),\n        dims=(\"x\", \"y\", \"t\"),\n        coords={\n            \"x\": np.arange(100),\n            \"y\": np.arange(100),\n            \"t\": np.arange(10),\n        }\n    )\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=10),\n        input_overlap=dict(x=5, y=5),\n    )\n    return bgen\n\n@pytest.mark.parametrize(\n    \"case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output\",\n    [\n        (\n            \"Resampling only: Downsample x, Upsample y\",\n            {'x': 5, 'y': 20},  \n            [],\n            [],\n            ['x', 'y'],\n            {'x': 50, 'y': 200} \n        ),\n        (\n            \"New dimensions only: Add a 'channel' dimension\",\n            {'channel': 3},\n            ['channel'],\n            [],\n            [],\n            {'channel': 3}\n        ),\n        (\n            \"Mixed: Resample x, add new channel dimension and keep t as core\",\n            {'x': 30, 'channel': 12}, \n            ['channel'],\n            ['t'],\n            ['x'],\n            {'x': 300, 'channel': 12} \n        ),\n        (\n            \"Identity resampling (ratio=1)\",\n            {'x': 10, 'y': 10},\n            [],\n            [],\n            ['x', 'y'],\n            {'x': 100, 'y': 100} \n        ),\n        (\n            \"Core dims only: 't' is a core dim\",\n            {'t': 10},\n            [], \n            ['t'], \n            [],\n            {'t': 10}\n        ),\n    ]\n)\ndef test_get_output_array_size_scenarios(\n    bgen_fixture,  # The fixture is passed as an argument\n    case_description,\n    output_tensor_dim,\n    new_dim,\n    core_dim,\n    resample_dim,\n    expected_output\n):\n    \"\"\"\n    Tests various valid scenarios for calculating the output array size.\n    The `case_description` parameter is not used in the code but helps make\n    test results more readable.\n    \"\"\"\n    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture\n    result = _get_output_array_size(\n        bgen=bgen_fixture,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        core_dim=core_dim,\n        resample_dim=resample_dim\n    )\n    \n    assert result == expected_output, f\"Failed on case: {case_description}\"\n\n%%writefile -a test_get_array_size.py\n\ndef test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a core_dim size doesn't match the source.\"\"\"\n    with pytest.raises(ValueError, match=\"does not equal the source data array size\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'t': 99}, new_dim=[], core_dim=['t'], resample_dim=[]\n        )\n\ndef test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a dimension is not specified in any category.\"\"\"\n    with pytest.raises(ValueError, match=\"must be specified in one of\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'x': 10}, new_dim=[], core_dim=[], resample_dim=[]\n        )\n\ndef test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):\n    \"\"\"Tests AssertionError when the resample ratio is not an integer or its inverse.\"\"\"\n    with pytest.raises(AssertionError, match=\"must be an integer or its inverse\"):\n        # 15 / 10 = 1.5, which is not a valid ratio\n        _get_resample_factor(bgen_fixture, output_tensor_dim={'x': 15}, resample_dim=['x'])\n\n!pytest -v test_get_array_size.py\n\n","type":"content","url":"/notebooks/inference-testing#testing-the-array-size-function","position":5},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"type":"lvl2","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":6},{"hierarchy":{"lvl1":"Infer model on array","lvl2":"Testing the predict_on_array function"},"content":"\n\n%%writefile test_predict_on_array.py\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *\n\ninput_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)\ninput_tensor[0,0,:]\n\nmodel = MeanAlongDim(-1)\nmodel(input_tensor)\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.fixture\ndef map_dataset_fixture() -> MapDataset:\n    \"\"\"\n    Creates a MapDataset with a predictable BatchGenerator for testing.\n    - Data is an xarray DataArray with dimensions x=20, y=10\n    - Values are a simple np.arange sequence for easy verification.\n    - Batches are size x=10, y=5 with overlap x=2, y=2\n    \"\"\"\n    # Using a smaller, more manageable dataset for testing\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )\n    return MapDataset(bgen)\n\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )\n\n%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\n    \"model, output_tensor_dim, new_dim, resample_dim, expected_transform\",\n    [\n        # Case 1: Resampling - Downsampling with a subset model\n        (\n            SubsetAlongAxis(ax=1, n=5), # Corresponds to 'x' dim in batch\n            {'x': 5, 'y': 5},\n            [],\n            ['x'],\n            lambda da: da.isel(x=slice(0, 5)) # Expected: take first 5 elements of original 'x'\n        ),\n        # Case 2: Dimension reduction with a mean model\n        (\n            MeanAlongDim(ax=2), # Corresponds to 'y' dim in batch\n            {'x': 10},\n            [],\n            ['x'],\n            lambda da: da.mean(dim='y') # Expected: mean along original 'y'\n        ),\n    ]\n)\ndef test_predict_on_array_reassembly(\n    map_dataset_fixture,\n    model,\n    output_tensor_dim,\n    new_dim,\n    resample_dim,\n    expected_transform\n):\n    \"\"\"\n    Tests that predict_on_array correctly reassembles batches from different models.\n    \"\"\"\n    # --- Run the function under test ---\n    # Using a small batch_size to ensure multiple iterations\n    predicted_da, predicted_n = predict_on_array(\n        dataset=map_dataset_fixture,\n        model=model,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        resample_dim=resample_dim,\n        batch_size=4 \n    )\n\n    # --- Manually calculate the expected result ---\n    bgen = map_dataset_fixture.generator\n    # 1. Create the expected output array structure\n    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, resample_dim)\n    expected_da = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))\n    expected_n = xr.full_like(expected_da, 0)\n\n    # 2. Manually iterate through batches and apply the same logic as the function\n    for i in range(len(map_dataset_fixture)):\n        batch_da = bgen[i]\n        \n        # Apply the same transformation the model would\n        transformed_batch = expected_transform(batch_da)\n        \n        # Get the rescaled indexer\n        old_indexer = bgen.batch_selectors[i]\n        new_indexer = {}\n        for key in old_indexer:\n            if key in resample_dim:\n                resample_ratio = output_tensor_dim[key] / bgen.input_dims[key]\n                new_indexer[key] = slice(\n                    int(old_indexer[key].start * resample_ratio),\n                    int(old_indexer[key].stop * resample_ratio)\n                )\n        \n        # Add the result to our manually calculated array\n        expected_da.loc[new_indexer] += transformed_batch.values\n        expected_n.loc[new_indexer] += 1\n\n    # --- Assert that the results are identical ---\n    # We test the raw summed output and the overlap counter array\n    xr.testing.assert_allclose(predicted_da, expected_da)\n    xr.testing.assert_allclose(predicted_n, expected_n)\n\n!pytest -v test_predict_on_array.py","type":"content","url":"/notebooks/inference-testing#testing-the-predict-on-array-function","position":7}]}