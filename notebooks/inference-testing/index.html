<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Infer model on array - Xbatcher for deep learning</title><meta property="og:title" content="Infer model on array - Xbatcher for deep learning"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/xbatcher-deep-learning/build/thumbnail-9d3533e06c20138ff98bb2ae816ee1eb.png"/><meta property="og:image" content="/xbatcher-deep-learning/build/thumbnail-9d3533e06c20138ff98bb2ae816ee1eb.png"/><link rel="stylesheet" href="/xbatcher-deep-learning/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/xbatcher-deep-learning/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-T52X8HNYE8"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-T52X8HNYE8');</script><link rel="icon" href="/xbatcher-deep-learning/favicon.ico"/><link rel="stylesheet" href="/xbatcher-deep-learning/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="https://projectpythia.org"><div class="p-1 mr-3"><img src="/xbatcher-deep-learning/build/config-item-24692dda-cdfca4d79038f49a4ab2d3de99186fd7.svg" class="h-9 dark:hidden" height="2.25rem"/><img src="/xbatcher-deep-learning/build/config-item-84d6d338-5e8d28df6d41746144e1ffe8445dee5d.svg" class="hidden h-9 dark:block" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Home</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://foundations.projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Foundations</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://cookbooks.projectpythia.org/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Cookbooks</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org/resource-gallery/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Resources</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org/#join-us" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Community</a></div></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"><div class="relative" data-headlessui-state=""><div><button class="flex text-sm bg-transparent rounded-full focus:outline-none" id="headlessui-menu-button-:Rr4op:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open Menu</span><div class="flex items-center text-stone-200 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="p-1"><path fill-rule="evenodd" d="M10.5 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z" clip-rule="evenodd"></path></svg></div></button></div></div></div><div class="hidden sm:block"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-block px-4 py-2 mx-1 mt-0 leading-none border rounded text-md border-stone-700 dark:border-white text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 hover:bg-neutral-100">Project Pythia</a></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Home</a><a href="https://foundations.projectpythia.org" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Foundations</a><a href="https://cookbooks.projectpythia.org/" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Cookbooks</a><a href="https://projectpythia.org/resource-gallery/" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Resources</a><a href="https://projectpythia.org/#join-us" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Community</a></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Xbatcher for deep learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/xbatcher-deep-learning/">Xbatcher for deep learning</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Preamble" class="block break-words rounded py-2 grow cursor-pointer">Preamble</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Testing model inference" class="block break-words rounded py-2 grow cursor-pointer">Testing model inference</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div title="Inference functions" class="block break-words rounded p-2 my-1 rounded-lg hover:bg-slate-300/30">Inference functions</div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://opensource.org/licenses/Apache-2.0" target="_blank" rel="noopener noreferrer" title="Code License: Apache License 2.0 (Apache-2.0)" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mx-1 inline-block opacity-60 hover:opacity-100 hover:text-[#599F46]"><path d="M13.2 15.6c1.4-.5 2.1-1.6 2.1-3.3S13.8 8.9 12 8.9c-1.9 0-3.3 1.6-3.3 3.3 0 1.8.8 3 2.2 3.4l-2.3 5.9c-3.1-.8-6.3-4.6-6.3-9.3 0-5.5 4.3-10 9.7-10s9.8 4.5 9.8 10c0 4.7-3.1 8.5-6.3 9.3l-2.3-5.9z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/projectpythia/xbatcher-deep-learning" title="GitHub Repository: projectpythia/xbatcher-deep-learning" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><a href="https://github.com/projectpythia/xbatcher-deep-learning/blob/main/notebooks/inference-testing.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div><button class="inline-flex size-[24px] hover:text-[#E18435] items-center justify-center" aria-label="Launch in external computing interface" title="Launch in external computing interface" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Re8top:" data-state="closed"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.85357 3.85355L7.65355 3.05353C8.2981 2.40901 9.42858 1.96172 10.552 1.80125C11.1056 1.72217 11.6291 1.71725 12.0564 1.78124C12.4987 1.84748 12.7698 1.97696 12.8965 2.10357C13.0231 2.23018 13.1526 2.50125 13.2188 2.94357C13.2828 3.37086 13.2779 3.89439 13.1988 4.44801C13.0383 5.57139 12.591 6.70188 11.9464 7.34645L7.49999 11.7929L6.35354 10.6465C6.15827 10.4512 5.84169 10.4512 5.64643 10.6465C5.45117 10.8417 5.45117 11.1583 5.64643 11.3536L7.14644 12.8536C7.34171 13.0488 7.65829 13.0488 7.85355 12.8536L8.40073 12.3064L9.57124 14.2572C9.65046 14.3893 9.78608 14.4774 9.9389 14.4963C10.0917 14.5151 10.2447 14.4624 10.3535 14.3536L12.3535 12.3536C12.4648 12.2423 12.5172 12.0851 12.495 11.9293L12.0303 8.67679L12.6536 8.05355C13.509 7.19808 14.0117 5.82855 14.1887 4.58943C14.2784 3.9618 14.2891 3.33847 14.2078 2.79546C14.1287 2.26748 13.9519 1.74482 13.6035 1.39645C13.2552 1.04809 12.7325 0.871332 12.2045 0.792264C11.6615 0.710945 11.0382 0.721644 10.4105 0.8113C9.17143 0.988306 7.80189 1.491 6.94644 2.34642L6.32322 2.96968L3.07071 2.50504C2.91492 2.48278 2.75773 2.53517 2.64645 2.64646L0.646451 4.64645C0.537579 4.75533 0.484938 4.90829 0.50375 5.0611C0.522563 5.21391 0.61073 5.34954 0.742757 5.42876L2.69364 6.59928L2.14646 7.14645C2.0527 7.24022 2.00002 7.3674 2.00002 7.50001C2.00002 7.63261 2.0527 7.75979 2.14646 7.85356L3.64647 9.35356C3.84173 9.54883 4.15831 9.54883 4.35357 9.35356C4.54884 9.1583 4.54884 8.84172 4.35357 8.64646L3.20712 7.50001L3.85357 6.85356L6.85357 3.85355ZM10.0993 13.1936L9.12959 11.5775L11.1464 9.56067L11.4697 11.8232L10.0993 13.1936ZM3.42251 5.87041L5.43935 3.85356L3.17678 3.53034L1.80638 4.90074L3.42251 5.87041ZM2.35356 10.3535C2.54882 10.1583 2.54882 9.8417 2.35356 9.64644C2.1583 9.45118 1.84171 9.45118 1.64645 9.64644L0.646451 10.6464C0.451188 10.8417 0.451188 11.1583 0.646451 11.3535C0.841713 11.5488 1.1583 11.5488 1.35356 11.3535L2.35356 10.3535ZM3.85358 11.8536C4.04884 11.6583 4.04885 11.3417 3.85359 11.1465C3.65833 10.9512 3.34175 10.9512 3.14648 11.1465L1.14645 13.1464C0.95119 13.3417 0.951187 13.6583 1.14645 13.8535C1.34171 14.0488 1.65829 14.0488 1.85355 13.8536L3.85358 11.8536ZM5.35356 13.3535C5.54882 13.1583 5.54882 12.8417 5.35356 12.6464C5.1583 12.4512 4.84171 12.4512 4.64645 12.6464L3.64645 13.6464C3.45119 13.8417 3.45119 14.1583 3.64645 14.3535C3.84171 14.5488 4.1583 14.5488 4.35356 14.3535L5.35356 13.3535ZM9.49997 6.74881C10.1897 6.74881 10.7488 6.1897 10.7488 5.5C10.7488 4.8103 10.1897 4.25118 9.49997 4.25118C8.81026 4.25118 8.25115 4.8103 8.25115 5.5C8.25115 6.1897 8.81026 6.74881 9.49997 6.74881Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div><h1 class="mb-0">Infer model on array</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78top:" data-state="closed">The Project Pythia Community</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div class="sticky top-[60px] pb-[14px] flex justify-end w-full z-20 pointer-events-none"><div class="flex p-1 m-1 space-x-1 border rounded-full shadow pointer-events-auto border-stone-300 bg-white/80 dark:bg-stone-900/80 backdrop-blur"><div class="rounded"><button class="flex text-center rounded-full cursor-pointer text-stone-800 dark:text-white hover:opacity-100 opacity-60" aria-label="start compute environment"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="inline-block w-6 h-6 align-top"><title>Launch kernel</title><path stroke-linecap="round" stroke-linejoin="round" d="M5.636 5.636a9 9 0 1 0 12.728 0M12 3v9"></path></svg></button></div></div></div><div id="skip-to-article"></div><div id="HGJtS2GbNo" class="relative group/block"><hr class="py-2 my-5 translate-y-2"/></div><div id="Rzxo4Gpqnp" class="relative group/block"><h2 id="imports" class="relative group"><span class="heading-text">Imports</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#imports" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="Z2kAPxJOfG" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import torch
import xbatcher
import xarray as xr
import numpy as np
import pytest

from functions import _get_output_array_size, predict_on_array</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="pB-Ky8H64VdJ2JmOVBJH9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="DaVAPpgko6" class="relative group/block"><h2 id="testing-the-array-size-function" class="relative group"><span class="heading-text">Testing the array size function</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#testing-the-array-size-function" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="QTfU0mIGQA" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile test_get_array_size.py
import torch
import xbatcher
import xarray as xr
import numpy as np
import pytest

from functions import _get_output_array_size, _get_resample_factor</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="z4NFP6BwGCmVsDnD2KgNe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Overwriting test_get_array_size.py
</span></code></pre></div></div></div><div id="irSbGAtSVE" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile -a test_get_array_size.py

@pytest.fixture
def bgen_fixture() -&gt; xbatcher.BatchGenerator:
    data = xr.DataArray(
        data=np.random.rand(100, 100, 10),
        dims=(&quot;x&quot;, &quot;y&quot;, &quot;t&quot;),
        coords={
            &quot;x&quot;: np.arange(100),
            &quot;y&quot;: np.arange(100),
            &quot;t&quot;: np.arange(10),
        }
    )
    
    bgen = xbatcher.BatchGenerator(
        data,
        input_dims=dict(x=10, y=10),
        input_overlap=dict(x=5, y=5),
    )
    return bgen

@pytest.mark.parametrize(
    &quot;case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output&quot;,
    [
        (
            &quot;Resampling only: Downsample x, Upsample y&quot;,
            {&#x27;x&#x27;: 5, &#x27;y&#x27;: 20},  
            [],
            [],
            [&#x27;x&#x27;, &#x27;y&#x27;],
            {&#x27;x&#x27;: 50, &#x27;y&#x27;: 200} 
        ),
        (
            &quot;New dimensions only: Add a &#x27;channel&#x27; dimension&quot;,
            {&#x27;channel&#x27;: 3},
            [&#x27;channel&#x27;],
            [],
            [],
            {&#x27;channel&#x27;: 3}
        ),
        (
            &quot;Mixed: Resample x, add new channel dimension and keep t as core&quot;,
            {&#x27;x&#x27;: 30, &#x27;channel&#x27;: 12}, 
            [&#x27;channel&#x27;],
            [&#x27;t&#x27;],
            [&#x27;x&#x27;],
            {&#x27;x&#x27;: 300, &#x27;channel&#x27;: 12} 
        ),
        (
            &quot;Identity resampling (ratio=1)&quot;,
            {&#x27;x&#x27;: 10, &#x27;y&#x27;: 10},
            [],
            [],
            [&#x27;x&#x27;, &#x27;y&#x27;],
            {&#x27;x&#x27;: 100, &#x27;y&#x27;: 100} 
        ),
        (
            &quot;Core dims only: &#x27;t&#x27; is a core dim&quot;,
            {&#x27;t&#x27;: 10},
            [], 
            [&#x27;t&#x27;], 
            [],
            {&#x27;t&#x27;: 10}
        ),
    ]
)
def test_get_output_array_size_scenarios(
    bgen_fixture,  # The fixture is passed as an argument
    case_description,
    output_tensor_dim,
    new_dim,
    core_dim,
    resample_dim,
    expected_output
):
    &quot;&quot;&quot;
    Tests various valid scenarios for calculating the output array size.
    The `case_description` parameter is not used in the code but helps make
    test results more readable.
    &quot;&quot;&quot;
    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture
    result = _get_output_array_size(
        bgen=bgen_fixture,
        output_tensor_dim=output_tensor_dim,
        new_dim=new_dim,
        core_dim=core_dim,
        resample_dim=resample_dim
    )
    
    assert result == expected_output, f&quot;Failed on case: {case_description}&quot;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="hNOUX1fiZa74KDAH6Z50O" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Appending to test_get_array_size.py
</span></code></pre></div></div></div><div id="beAobmWMNR" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile -a test_get_array_size.py

def test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):
    &quot;&quot;&quot;Tests ValueError when a core_dim size doesn&#x27;t match the source.&quot;&quot;&quot;
    with pytest.raises(ValueError, match=&quot;does not equal the source data array size&quot;):
        _get_output_array_size(
            bgen_fixture, output_tensor_dim={&#x27;t&#x27;: 99}, new_dim=[], core_dim=[&#x27;t&#x27;], resample_dim=[]
        )

def test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):
    &quot;&quot;&quot;Tests ValueError when a dimension is not specified in any category.&quot;&quot;&quot;
    with pytest.raises(ValueError, match=&quot;must be specified in one of&quot;):
        _get_output_array_size(
            bgen_fixture, output_tensor_dim={&#x27;x&#x27;: 10}, new_dim=[], core_dim=[], resample_dim=[]
        )

def test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):
    &quot;&quot;&quot;Tests AssertionError when the resample ratio is not an integer or its inverse.&quot;&quot;&quot;
    with pytest.raises(AssertionError, match=&quot;must be an integer or its inverse&quot;):
        # 15 / 10 = 1.5, which is not a valid ratio
        _get_resample_factor(bgen_fixture, output_tensor_dim={&#x27;x&#x27;: 15}, resample_dim=[&#x27;x&#x27;])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="o8LOlrqvHRKSdMmfF0vMR" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Appending to test_get_array_size.py
</span></code></pre></div></div></div><div id="NLMDwftduI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">!pytest -v test_get_array_size.py</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ag3DZW8ipIusWt8K17Kxb" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span style="font-weight:bold">============================= test session starts ==============================</span><span>
platform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13
cachedir: .pytest_cache
rootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks
plugins: anyio-4.10.0
</span><span style="font-weight:bold">collecting ... </span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>collected 8 items                                                              </span><span style="font-weight:bold">

test_get_array_size.py::test_get_output_array_size_scenarios[Resampling only: Downsample x, Upsample y-output_tensor_dim0-new_dim0-core_dim0-resample_dim0-expected_output0] </span><span style="color:rgb(0, 187, 0);font-weight:bold">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 12%]</span><span>
test_get_array_size.py::test_get_output_array_size_scenarios[New dimensions only: Add a &#x27;channel&#x27; dimension-output_tensor_dim1-new_dim1-core_dim1-resample_dim1-expected_output1] </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 25%]</span><span>
test_get_array_size.py::test_get_output_array_size_scenarios[Mixed: Resample x, add new channel dimension and keep t as core-output_tensor_dim2-new_dim2-core_dim2-resample_dim2-expected_output2] </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 37%]</span><span>
test_get_array_size.py::test_get_output_array_size_scenarios[Identity resampling (ratio=1)-output_tensor_dim3-new_dim3-core_dim3-resample_dim3-expected_output3] </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 50%]</span><span>
test_get_array_size.py::test_get_output_array_size_scenarios[Core dims only: &#x27;t&#x27; is a core dim-output_tensor_dim4-new_dim4-core_dim4-resample_dim4-expected_output4] </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 62%]</span><span>
test_get_array_size.py::test_get_output_array_size_raises_error_on_mismatched_core_dim </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 75%]</span><span>
test_get_array_size.py::test_get_output_array_size_raises_error_on_unspecified_dim </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [ 87%]</span><span>
test_get_array_size.py::test_get_resample_factor_raises_error_on_invalid_ratio </span><span style="color:rgb(0, 187, 0)">PASSED</span><span style="color:rgb(0, 187, 0)"> [100%]</span><span>

</span><span style="color:rgb(0, 187, 0)">============================== </span><span style="color:rgb(0, 187, 0);font-weight:bold">8 passed</span><span style="color:rgb(0, 187, 0)"> in 1.51s</span><span style="color:rgb(0, 187, 0)"> ===============================</span><span>
</span></code></pre></div></div></div><div id="pbFBRXiFrB" class="relative group/block"><h2 id="testing-the-predict-on-array-function" class="relative group"><span class="heading-text">Testing the predict_on_array function</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#testing-the-predict-on-array-function" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="oZQ7a8kZPG" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile test_predict_on_array.py
import xarray as xr
import numpy as np
import torch
import xbatcher
import pytest
from xbatcher.loaders.torch import MapDataset

from functions import _get_output_array_size, predict_on_array
from dummy_models import *</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="TdlxPgEtIi7kSpg0N3ffp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Overwriting test_predict_on_array.py
</span></code></pre></div></div></div><div id="OsaVrgJTJA" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import xarray as xr
import numpy as np
import torch
import xbatcher
import pytest
from xbatcher.loaders.torch import MapDataset

from functions import _get_output_array_size, predict_on_array
from dummy_models import *</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ibfotUOe_qzAYxZGuAkh8" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="tqtbBjKaNx" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">input_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)
input_tensor[0,0,:]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="bbHMxLRXRcI4D5w8xIXyw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>tensor([0., 1., 2., 3., 4.])</span></code></div></div></div><div id="PtLyGHjm2m" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model = MeanAlongDim(-1)
model(input_tensor)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="LiKyOJoevc0fybdPNeOBF" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>tensor([[  2.,   7.,  12.,  17.,  22.],
        [ 27.,  32.,  37.,  42.,  47.],
        [ 52.,  57.,  62.,  67.,  72.],
        [ 77.,  82.,  87.,  92.,  97.],
        [102., 107., 112., 117., 122.]])</span></code></div></div></div><div id="m1Z8vLVFyQ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile -a test_predict_on_array.py

@pytest.fixture
def map_dataset_fixture() -&gt; MapDataset:
    &quot;&quot;&quot;
    Creates a MapDataset with a predictable BatchGenerator for testing.
    - Data is an xarray DataArray with dimensions x=20, y=10
    - Values are a simple np.arange sequence for easy verification.
    - Batches are size x=10, y=5 with overlap x=2, y=2
    &quot;&quot;&quot;
    # Using a smaller, more manageable dataset for testing
    data = xr.DataArray(
        data=np.arange(20 * 10).reshape(20, 10),
        dims=(&quot;x&quot;, &quot;y&quot;),
        coords={&quot;x&quot;: np.arange(20), &quot;y&quot;: np.arange(10)}
    ).astype(float)
    
    bgen = xbatcher.BatchGenerator(
        data,
        input_dims=dict(x=10, y=5),
        input_overlap=dict(x=2, y=2),
    )
    return MapDataset(bgen)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="7eOyvxp9t0Xwbbnx1Csyz" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Appending to test_predict_on_array.py
</span></code></pre></div></div></div><div id="bRR8L0o3nV" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">    data = xr.DataArray(
        data=np.arange(20 * 10).reshape(20, 10),
        dims=(&quot;x&quot;, &quot;y&quot;),
        coords={&quot;x&quot;: np.arange(20), &quot;y&quot;: np.arange(10)}
    ).astype(float)
    
    bgen = xbatcher.BatchGenerator(
        data,
        input_dims=dict(x=10, y=5),
        input_overlap=dict(x=2, y=2),
    )</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="_4EsFmrUXaF8QWzDOhdxR" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="cEAo2LM2fY" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">%%writefile -a test_predict_on_array.py

@pytest.mark.parametrize(
    &quot;model, output_tensor_dim, new_dim, resample_dim, expected_transform&quot;,
    [
        # Case 1: Resampling - Downsampling with a subset model
        (
            SubsetAlongAxis(ax=1, n=5), # Corresponds to &#x27;x&#x27; dim in batch
            {&#x27;x&#x27;: 5, &#x27;y&#x27;: 5},
            [],
            [&#x27;x&#x27;],
            lambda da: da.isel(x=slice(0, 5)) # Expected: take first 5 elements of original &#x27;x&#x27;
        ),
        # Case 2: Dimension reduction with a mean model
        (
            MeanAlongDim(ax=2), # Corresponds to &#x27;y&#x27; dim in batch
            {&#x27;x&#x27;: 10},
            [],
            [&#x27;x&#x27;],
            lambda da: da.mean(dim=&#x27;y&#x27;) # Expected: mean along original &#x27;y&#x27;
        ),
    ]
)
def test_predict_on_array_reassembly(
    map_dataset_fixture,
    model,
    output_tensor_dim,
    new_dim,
    resample_dim,
    expected_transform
):
    &quot;&quot;&quot;
    Tests that predict_on_array correctly reassembles batches from different models.
    &quot;&quot;&quot;
    # --- Run the function under test ---
    # Using a small batch_size to ensure multiple iterations
    predicted_da, predicted_n = predict_on_array(
        dataset=map_dataset_fixture,
        model=model,
        output_tensor_dim=output_tensor_dim,
        new_dim=new_dim,
        resample_dim=resample_dim,
        batch_size=4 
    )

    # --- Manually calculate the expected result ---
    bgen = map_dataset_fixture.generator
    # 1. Create the expected output array structure
    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, resample_dim)
    expected_da = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))
    expected_n = xr.full_like(expected_da, 0)

    # 2. Manually iterate through batches and apply the same logic as the function
    for i in range(len(map_dataset_fixture)):
        batch_da = bgen[i]
        
        # Apply the same transformation the model would
        transformed_batch = expected_transform(batch_da)
        
        # Get the rescaled indexer
        old_indexer = bgen.batch_selectors[i]
        new_indexer = {}
        for key in old_indexer:
            if key in resample_dim:
                resample_ratio = output_tensor_dim[key] / bgen.input_dims[key]
                new_indexer[key] = slice(
                    int(old_indexer[key].start * resample_ratio),
                    int(old_indexer[key].stop * resample_ratio)
                )
        
        # Add the result to our manually calculated array
        expected_da.loc[new_indexer] += transformed_batch.values
        expected_n.loc[new_indexer] += 1

    # --- Assert that the results are identical ---
    # We test the raw summed output and the overlap counter array
    xr.testing.assert_allclose(predicted_da, expected_da)
    xr.testing.assert_allclose(predicted_n, expected_n)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="N51vPbZ9KwgHGCaTaWQUv" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Appending to test_predict_on_array.py
</span></code></pre></div></div></div><div id="cwnU5HNSVs" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">!pytest -v test_predict_on_array.py</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="iHUkEUQb-caZhXd1VPZPD" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span style="font-weight:bold">============================= test session starts ==============================</span><span>
platform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13
cachedir: .pytest_cache
rootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks
plugins: anyio-4.10.0
</span><span style="font-weight:bold">collecting ... </span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>collected 2 items                                                              </span><span style="font-weight:bold">

test_predict_on_array.py::test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-&lt;lambda&gt;] </span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span style="color:rgb(187, 0, 0)">FAILED</span><span style="color:rgb(187, 0, 0)"> [ 50%]</span><span>
test_predict_on_array.py::test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-&lt;lambda&gt;] </span><span style="color:rgb(187, 0, 0)">FAILED</span><span style="color:rgb(187, 0, 0)"> [100%]</span><span>

=================================== FAILURES ===================================
</span><span style="color:rgb(187, 0, 0);font-weight:bold">_ test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-&lt;lambda&gt;] _</span><span>

map_dataset_fixture = &lt;xbatcher.loaders.torch.MapDataset object at 0x7fbeb9544590&gt;
model = SubsetAlongAxis(), output_tensor_dim = {&#x27;x&#x27;: 5, &#x27;y&#x27;: 5}, new_dim = []
resample_dim = [&#x27;x&#x27;], expected_transform = &lt;function &lt;lambda&gt; at 0x7fbeb9368860&gt;

    </span><span style="color:rgb(255,255,255)">@pytest</span><span>.mark.parametrize(</span><span>
        </span><span style="color:rgb(187, 187, 0)">&quot;</span><span style="color:rgb(187, 187, 0)">model, output_tensor_dim, new_dim, resample_dim, expected_transform</span><span style="color:rgb(187, 187, 0)">&quot;</span><span>,</span><span>
        [</span><span>
            </span><span style="color:rgb(85, 85, 85)"># Case 1: Resampling - Downsampling with a subset model</span><span>
            (</span><span>
                SubsetAlongAxis(ax=</span><span style="color:rgb(85, 85, 255)">1</span><span>, n=</span><span style="color:rgb(85, 85, 255)">5</span><span>), </span><span style="color:rgb(85, 85, 85)"># Corresponds to &#x27;x&#x27; dim in batch</span><span>
                {</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">5</span><span>, </span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">y</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">5</span><span>},</span><span>
                [],</span><span>
                [</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>],</span><span>
                </span><span style="color:rgb(85, 85, 255)">lambda</span><span> da: da.isel(x=</span><span style="color:rgb(85, 255, 255)">slice</span><span>(</span><span style="color:rgb(85, 85, 255)">0</span><span>, </span><span style="color:rgb(85, 85, 255)">5</span><span>)) </span><span style="color:rgb(85, 85, 85)"># Expected: take first 5 elements of original &#x27;x&#x27;</span><span>
            ),</span><span>
            </span><span style="color:rgb(85, 85, 85)"># Case 2: Dimension reduction with a mean model</span><span>
            (</span><span>
                MeanAlongDim(ax=</span><span style="color:rgb(85, 85, 255)">2</span><span>), </span><span style="color:rgb(85, 85, 85)"># Corresponds to &#x27;y&#x27; dim in batch</span><span>
                {</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">10</span><span>},</span><span>
                [],</span><span>
                [</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>],</span><span>
                </span><span style="color:rgb(85, 85, 255)">lambda</span><span> da: da.mean(dim=</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">y</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>) </span><span style="color:rgb(85, 85, 85)"># Expected: mean along original &#x27;y&#x27;</span><span>
            ),</span><span>
        ]</span><span>
    )</span><span>
    </span><span style="color:rgb(85, 85, 255)">def</span><span style="color:rgb(85, 85, 85)"> </span><span style="color:rgb(0, 255, 0)">test_predict_on_array_reassembly</span><span>(</span><span>
        map_dataset_fixture,</span><span>
        model,</span><span>
        output_tensor_dim,</span><span>
        new_dim,</span><span>
        resample_dim,</span><span>
        expected_transform</span><span>
    ):</span><span>
    </span><span style="color:rgb(85, 85, 85)">    </span><span style="color:rgb(187, 187, 0)">&quot;&quot;&quot;</span><span>
    </span><span style="color:rgb(187, 187, 0)">    Tests that predict_on_array correctly reassembles batches from different models.</span><span>
    </span><span style="color:rgb(187, 187, 0)">    &quot;&quot;&quot;</span><span>
        </span><span style="color:rgb(85, 85, 85)"># --- Run the function under test ---</span><span>
        </span><span style="color:rgb(85, 85, 85)"># Using a small batch_size to ensure multiple iterations</span><span>
&gt;       predicted_da, predicted_n = predict_on_array(</span><span>
            dataset=map_dataset_fixture,</span><span>
            model=model,</span><span>
            output_tensor_dim=output_tensor_dim,</span><span>
            new_dim=new_dim,</span><span>
            resample_dim=resample_dim,</span><span>
            batch_size=</span><span style="color:rgb(85, 85, 255)">4</span><span>
        )</span><span>
</span><span style="color:rgb(187, 0, 0);font-weight:bold">E       TypeError: predict_on_array() missing 1 required positional argument: &#x27;core_dim&#x27;</span><span>

</span><span style="color:rgb(187, 0, 0);font-weight:bold">test_predict_on_array.py</span><span>:67: TypeError
</span><span style="color:rgb(187, 0, 0);font-weight:bold">_ test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-&lt;lambda&gt;] _</span><span>

map_dataset_fixture = &lt;xbatcher.loaders.torch.MapDataset object at 0x7fbeb948a490&gt;
model = MeanAlongDim(), output_tensor_dim = {&#x27;x&#x27;: 10}, new_dim = []
resample_dim = [&#x27;x&#x27;], expected_transform = &lt;function &lt;lambda&gt; at 0x7fbeb9368e00&gt;

    </span><span style="color:rgb(255,255,255)">@pytest</span><span>.mark.parametrize(</span><span>
        </span><span style="color:rgb(187, 187, 0)">&quot;</span><span style="color:rgb(187, 187, 0)">model, output_tensor_dim, new_dim, resample_dim, expected_transform</span><span style="color:rgb(187, 187, 0)">&quot;</span><span>,</span><span>
        [</span><span>
            </span><span style="color:rgb(85, 85, 85)"># Case 1: Resampling - Downsampling with a subset model</span><span>
            (</span><span>
                SubsetAlongAxis(ax=</span><span style="color:rgb(85, 85, 255)">1</span><span>, n=</span><span style="color:rgb(85, 85, 255)">5</span><span>), </span><span style="color:rgb(85, 85, 85)"># Corresponds to &#x27;x&#x27; dim in batch</span><span>
                {</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">5</span><span>, </span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">y</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">5</span><span>},</span><span>
                [],</span><span>
                [</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>],</span><span>
                </span><span style="color:rgb(85, 85, 255)">lambda</span><span> da: da.isel(x=</span><span style="color:rgb(85, 255, 255)">slice</span><span>(</span><span style="color:rgb(85, 85, 255)">0</span><span>, </span><span style="color:rgb(85, 85, 255)">5</span><span>)) </span><span style="color:rgb(85, 85, 85)"># Expected: take first 5 elements of original &#x27;x&#x27;</span><span>
            ),</span><span>
            </span><span style="color:rgb(85, 85, 85)"># Case 2: Dimension reduction with a mean model</span><span>
            (</span><span>
                MeanAlongDim(ax=</span><span style="color:rgb(85, 85, 255)">2</span><span>), </span><span style="color:rgb(85, 85, 85)"># Corresponds to &#x27;y&#x27; dim in batch</span><span>
                {</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>: </span><span style="color:rgb(85, 85, 255)">10</span><span>},</span><span>
                [],</span><span>
                [</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">x</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>],</span><span>
                </span><span style="color:rgb(85, 85, 255)">lambda</span><span> da: da.mean(dim=</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span style="color:rgb(187, 187, 0)">y</span><span style="color:rgb(187, 187, 0)">&#x27;</span><span>) </span><span style="color:rgb(85, 85, 85)"># Expected: mean along original &#x27;y&#x27;</span><span>
            ),</span><span>
        ]</span><span>
    )</span><span>
    </span><span style="color:rgb(85, 85, 255)">def</span><span style="color:rgb(85, 85, 85)"> </span><span style="color:rgb(0, 255, 0)">test_predict_on_array_reassembly</span><span>(</span><span>
        map_dataset_fixture,</span><span>
        model,</span><span>
        output_tensor_dim,</span><span>
        new_dim,</span><span>
        resample_dim,</span><span>
        expected_transform</span><span>
    ):</span><span>
    </span><span style="color:rgb(85, 85, 85)">    </span><span style="color:rgb(187, 187, 0)">&quot;&quot;&quot;</span><span>
    </span><span style="color:rgb(187, 187, 0)">    Tests that predict_on_array correctly reassembles batches from different models.</span><span>
    </span><span style="color:rgb(187, 187, 0)">    &quot;&quot;&quot;</span><span>
        </span><span style="color:rgb(85, 85, 85)"># --- Run the function under test ---</span><span>
        </span><span style="color:rgb(85, 85, 85)"># Using a small batch_size to ensure multiple iterations</span><span>
&gt;       predicted_da, predicted_n = predict_on_array(</span><span>
            dataset=map_dataset_fixture,</span><span>
            model=model,</span><span>
            output_tensor_dim=output_tensor_dim,</span><span>
            new_dim=new_dim,</span><span>
            resample_dim=resample_dim,</span><span>
            batch_size=</span><span style="color:rgb(85, 85, 255)">4</span><span>
        )</span><span>
</span><span style="color:rgb(187, 0, 0);font-weight:bold">E       TypeError: predict_on_array() missing 1 required positional argument: &#x27;core_dim&#x27;</span><span>

</span><span style="color:rgb(187, 0, 0);font-weight:bold">test_predict_on_array.py</span><span>:67: TypeError
</span><span style="color:rgb(0, 187, 187);font-weight:bold">=========================== short test summary info ============================</span><span>
</span><span style="color:rgb(187, 0, 0)">FAILED</span><span> test_predict_on_array.py::</span><span style="font-weight:bold">test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-&lt;lambda&gt;]</span><span> - TypeError: predict_on_array() missing 1 required positional argument: &#x27;core_dim&#x27;
</span><span style="color:rgb(187, 0, 0)">FAILED</span><span> test_predict_on_array.py::</span><span style="font-weight:bold">test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-&lt;lambda&gt;]</span><span> - TypeError: predict_on_array() missing 1 required positional argument: &#x27;core_dim&#x27;
</span><span style="color:rgb(187, 0, 0)">============================== </span><span style="color:rgb(187, 0, 0);font-weight:bold">2 failed</span><span style="color:rgb(187, 0, 0)"> in 1.57s</span><span style="color:rgb(187, 0, 0)"> ===============================</span><span>
</span></code></pre></div></div></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/xbatcher-deep-learning/notebooks/how-to-cite"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Preamble</div>How to Cite This Cookbook</div></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/xbatcher-deep-learning/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-JSE36H2O.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/root-IB5726YR.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/_shared/chunk-NBON2RSI.js"/><link rel="modulepreload" href="/xbatcher-deep-learning/build/routes/$-LXLHKVOR.js"/><script>window.__remixContext = {"url":"/notebooks/inference-testing","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/xbatcher-deep-learning/build/config-item-9b3afca6-fa2f51aea372b822fcb0f8615311ffc0.ico","logo":"/xbatcher-deep-learning/build/config-item-24692dda-cdfca4d79038f49a4ab2d3de99186fd7.svg","logo_dark":"/xbatcher-deep-learning/build/config-item-84d6d338-5e8d28df6d41746144e1ffe8445dee5d.svg","logo_url":"https://projectpythia.org","analytics_google":"G-T52X8HNYE8","folders":true},"parts":{},"nav":[{"title":"Home","url":"https://projectpythia.org"},{"title":"Foundations","url":"https://foundations.projectpythia.org"},{"title":"Cookbooks","url":"https://cookbooks.projectpythia.org/"},{"title":"Resources","url":"https://projectpythia.org/resource-gallery/"},{"title":"Community","url":"https://projectpythia.org/#join-us"}],"actions":[{"title":"Project Pythia","url":"https://projectpythia.org","internal":false,"static":false}],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Xbatcher for deep learning","authors":[{"nameParsed":{"literal":"The Project Pythia Community","given":"The Project Pythia","family":"Community"},"name":"The Project Pythia Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/projectpythia/xbatcher-deep-learning","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2024","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/xbatcher-deep-learning","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/inference-testing.ipynb"}],"title":"Testing model inference"},{"children":[{"file":"notebooks/functions.ipynb"}],"title":"Inference functions"}],"thumbnail":"/xbatcher-deep-learning/build/thumbnail-9d3533e06c20138ff98bb2ae816ee1eb.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/xbatcher-deep-learning/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Testing model inference"},{"slug":"notebooks.inference-testing","title":"Infer model on array","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Inference functions"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/xbatcher-deep-learning"},"routes/$":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/xbatcher-deep-learning/build/config-item-9b3afca6-fa2f51aea372b822fcb0f8615311ffc0.ico","logo":"/xbatcher-deep-learning/build/config-item-24692dda-cdfca4d79038f49a4ab2d3de99186fd7.svg","logo_dark":"/xbatcher-deep-learning/build/config-item-84d6d338-5e8d28df6d41746144e1ffe8445dee5d.svg","logo_url":"https://projectpythia.org","analytics_google":"G-T52X8HNYE8","folders":true},"parts":{},"nav":[{"title":"Home","url":"https://projectpythia.org"},{"title":"Foundations","url":"https://foundations.projectpythia.org"},{"title":"Cookbooks","url":"https://cookbooks.projectpythia.org/"},{"title":"Resources","url":"https://projectpythia.org/resource-gallery/"},{"title":"Community","url":"https://projectpythia.org/#join-us"}],"actions":[{"title":"Project Pythia","url":"https://projectpythia.org","internal":false,"static":false}],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Xbatcher for deep learning","authors":[{"nameParsed":{"literal":"The Project Pythia Community","given":"The Project Pythia","family":"Community"},"name":"The Project Pythia Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/projectpythia/xbatcher-deep-learning","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2024","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/xbatcher-deep-learning","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/inference-testing.ipynb"}],"title":"Testing model inference"},{"children":[{"file":"notebooks/functions.ipynb"}],"title":"Inference functions"}],"thumbnail":"/xbatcher-deep-learning/build/thumbnail-9d3533e06c20138ff98bb2ae816ee1eb.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/xbatcher-deep-learning/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Testing model inference"},{"slug":"notebooks.inference-testing","title":"Infer model on array","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Inference functions"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"6bbc48cf512f0a09654786745457af79ed39b263df10bd7e88f213656a365b8a","slug":"notebooks.inference-testing","location":"/notebooks/inference-testing.ipynb","dependencies":[],"frontmatter":{"title":"Infer model on array","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"cookbook-dev","language":"python"},"authors":[{"nameParsed":{"literal":"The Project Pythia Community","given":"The Project Pythia","family":"Community"},"name":"The Project Pythia Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/projectpythia/xbatcher-deep-learning","copyright":"2024","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/projectpythia/xbatcher-deep-learning/blob/main/notebooks/inference-testing.ipynb","exports":[{"format":"ipynb","filename":"inference-testing.ipynb","url":"/xbatcher-deep-learning/build/inference-testing-6eecc46a379422ed6e1e4a0d54f82565.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"thematicBreak","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UpVfMYCcZv"}],"key":"HGJtS2GbNo"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Imports","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pVudlxS5vz"}],"identifier":"imports","label":"Imports","html_id":"imports","implicit":true,"key":"AkmFuc5zaw"}],"key":"Rzxo4Gpqnp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, predict_on_array","key":"eR6LOL0Ypk"},{"type":"output","id":"pB-Ky8H64VdJ2JmOVBJH9","data":[],"key":"bzoQHMAHFM"}],"key":"Z2kAPxJOfG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Testing the array size function","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QzLlTH6ALR"}],"identifier":"testing-the-array-size-function","label":"Testing the array size function","html_id":"testing-the-array-size-function","implicit":true,"key":"nAgJQhI2fs"}],"key":"DaVAPpgko6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile test_get_array_size.py\nimport torch\nimport xbatcher\nimport xarray as xr\nimport numpy as np\nimport pytest\n\nfrom functions import _get_output_array_size, _get_resample_factor","key":"blQbqx2uXh"},{"type":"output","id":"z4NFP6BwGCmVsDnD2KgNe","data":[{"output_type":"stream","name":"stdout","text":"Overwriting test_get_array_size.py\n"}],"key":"Q7Sa8oEtiN"}],"key":"QTfU0mIGQA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_get_array_size.py\n\n@pytest.fixture\ndef bgen_fixture() -\u003e xbatcher.BatchGenerator:\n    data = xr.DataArray(\n        data=np.random.rand(100, 100, 10),\n        dims=(\"x\", \"y\", \"t\"),\n        coords={\n            \"x\": np.arange(100),\n            \"y\": np.arange(100),\n            \"t\": np.arange(10),\n        }\n    )\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=10),\n        input_overlap=dict(x=5, y=5),\n    )\n    return bgen\n\n@pytest.mark.parametrize(\n    \"case_description, output_tensor_dim, new_dim, core_dim, resample_dim, expected_output\",\n    [\n        (\n            \"Resampling only: Downsample x, Upsample y\",\n            {'x': 5, 'y': 20},  \n            [],\n            [],\n            ['x', 'y'],\n            {'x': 50, 'y': 200} \n        ),\n        (\n            \"New dimensions only: Add a 'channel' dimension\",\n            {'channel': 3},\n            ['channel'],\n            [],\n            [],\n            {'channel': 3}\n        ),\n        (\n            \"Mixed: Resample x, add new channel dimension and keep t as core\",\n            {'x': 30, 'channel': 12}, \n            ['channel'],\n            ['t'],\n            ['x'],\n            {'x': 300, 'channel': 12} \n        ),\n        (\n            \"Identity resampling (ratio=1)\",\n            {'x': 10, 'y': 10},\n            [],\n            [],\n            ['x', 'y'],\n            {'x': 100, 'y': 100} \n        ),\n        (\n            \"Core dims only: 't' is a core dim\",\n            {'t': 10},\n            [], \n            ['t'], \n            [],\n            {'t': 10}\n        ),\n    ]\n)\ndef test_get_output_array_size_scenarios(\n    bgen_fixture,  # The fixture is passed as an argument\n    case_description,\n    output_tensor_dim,\n    new_dim,\n    core_dim,\n    resample_dim,\n    expected_output\n):\n    \"\"\"\n    Tests various valid scenarios for calculating the output array size.\n    The `case_description` parameter is not used in the code but helps make\n    test results more readable.\n    \"\"\"\n    # The `bgen_fixture` argument is the BatchGenerator instance created by our fixture\n    result = _get_output_array_size(\n        bgen=bgen_fixture,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        core_dim=core_dim,\n        resample_dim=resample_dim\n    )\n    \n    assert result == expected_output, f\"Failed on case: {case_description}\"","key":"KHkmMcM6TQ"},{"type":"output","id":"hNOUX1fiZa74KDAH6Z50O","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_get_array_size.py\n"}],"key":"wtEdZllR3K"}],"key":"irSbGAtSVE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_get_array_size.py\n\ndef test_get_output_array_size_raises_error_on_mismatched_core_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a core_dim size doesn't match the source.\"\"\"\n    with pytest.raises(ValueError, match=\"does not equal the source data array size\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'t': 99}, new_dim=[], core_dim=['t'], resample_dim=[]\n        )\n\ndef test_get_output_array_size_raises_error_on_unspecified_dim(bgen_fixture):\n    \"\"\"Tests ValueError when a dimension is not specified in any category.\"\"\"\n    with pytest.raises(ValueError, match=\"must be specified in one of\"):\n        _get_output_array_size(\n            bgen_fixture, output_tensor_dim={'x': 10}, new_dim=[], core_dim=[], resample_dim=[]\n        )\n\ndef test_get_resample_factor_raises_error_on_invalid_ratio(bgen_fixture):\n    \"\"\"Tests AssertionError when the resample ratio is not an integer or its inverse.\"\"\"\n    with pytest.raises(AssertionError, match=\"must be an integer or its inverse\"):\n        # 15 / 10 = 1.5, which is not a valid ratio\n        _get_resample_factor(bgen_fixture, output_tensor_dim={'x': 15}, resample_dim=['x'])","key":"GtGxrgBM30"},{"type":"output","id":"o8LOlrqvHRKSdMmfF0vMR","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_get_array_size.py\n"}],"key":"jMpg8naT5d"}],"key":"beAobmWMNR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"!pytest -v test_get_array_size.py","key":"t7TMRvFssj"},{"type":"output","id":"ag3DZW8ipIusWt8K17Kxb","data":[{"output_type":"stream","name":"stdout","text":"\u001b[1m============================= test session starts ==============================\u001b[0m\r\nplatform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13\r\ncachedir: .pytest_cache\r\nrootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks\r\nplugins: anyio-4.10.0\r\n\u001b[1mcollecting ... \u001b[0m"},{"output_type":"stream","name":"stdout","text":"\u001b[1m\rcollecting 8 items                                                             \u001b[0m\u001b[1m\rcollected 8 items                                                              \u001b[0m\r\n\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Resampling only: Downsample x, Upsample y-output_tensor_dim0-new_dim0-core_dim0-resample_dim0-expected_output0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[New dimensions only: Add a 'channel' dimension-output_tensor_dim1-new_dim1-core_dim1-resample_dim1-expected_output1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Mixed: Resample x, add new channel dimension and keep t as core-output_tensor_dim2-new_dim2-core_dim2-resample_dim2-expected_output2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Identity resampling (ratio=1)-output_tensor_dim3-new_dim3-core_dim3-resample_dim3-expected_output3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_scenarios[Core dims only: 't' is a core dim-output_tensor_dim4-new_dim4-core_dim4-resample_dim4-expected_output4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_raises_error_on_mismatched_core_dim \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\r\ntest_get_array_size.py::test_get_output_array_size_raises_error_on_unspecified_dim \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\r\ntest_get_array_size.py::test_get_resample_factor_raises_error_on_invalid_ratio \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\r\n\r\n\u001b[32m============================== \u001b[32m\u001b[1m8 passed\u001b[0m\u001b[32m in 1.51s\u001b[0m\u001b[32m ===============================\u001b[0m\r\n"}],"key":"TnzDwvAUxL"}],"key":"NLMDwftduI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Testing the predict_on_array function","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GiDsLmjVtX"}],"identifier":"testing-the-predict-on-array-function","label":"Testing the predict_on_array function","html_id":"testing-the-predict-on-array-function","implicit":true,"key":"u5gbqv2Mxm"}],"key":"pbFBRXiFrB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile test_predict_on_array.py\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *","key":"xGRzE6bEZk"},{"type":"output","id":"TdlxPgEtIi7kSpg0N3ffp","data":[{"output_type":"stream","name":"stdout","text":"Overwriting test_predict_on_array.py\n"}],"key":"fOCMPAk4At"}],"key":"oZQ7a8kZPG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nimport pytest\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom functions import _get_output_array_size, predict_on_array\nfrom dummy_models import *","key":"SVO2zAj7Me"},{"type":"output","id":"ibfotUOe_qzAYxZGuAkh8","data":[],"key":"dIgDHhQnZu"}],"key":"OsaVrgJTJA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"input_tensor = torch.arange(125).reshape((5, 5, 5)).to(torch.float32)\ninput_tensor[0,0,:]","key":"xxoFr3Kj7h"},{"type":"output","id":"bbHMxLRXRcI4D5w8xIXyw","data":[{"output_type":"execute_result","execution_count":8,"metadata":{},"data":{"text/plain":{"content":"tensor([0., 1., 2., 3., 4.])","content_type":"text/plain"}}}],"key":"KCG7Di3VmR"}],"key":"tqtbBjKaNx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model = MeanAlongDim(-1)\nmodel(input_tensor)","key":"Jsx2yRp41S"},{"type":"output","id":"LiKyOJoevc0fybdPNeOBF","data":[{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"tensor([[  2.,   7.,  12.,  17.,  22.],\n        [ 27.,  32.,  37.,  42.,  47.],\n        [ 52.,  57.,  62.,  67.,  72.],\n        [ 77.,  82.,  87.,  92.,  97.],\n        [102., 107., 112., 117., 122.]])","content_type":"text/plain"}}}],"key":"CBlTW6oGx0"}],"key":"PtLyGHjm2m"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_predict_on_array.py\n\n@pytest.fixture\ndef map_dataset_fixture() -\u003e MapDataset:\n    \"\"\"\n    Creates a MapDataset with a predictable BatchGenerator for testing.\n    - Data is an xarray DataArray with dimensions x=20, y=10\n    - Values are a simple np.arange sequence for easy verification.\n    - Batches are size x=10, y=5 with overlap x=2, y=2\n    \"\"\"\n    # Using a smaller, more manageable dataset for testing\n    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )\n    return MapDataset(bgen)","key":"r3mIksx1AU"},{"type":"output","id":"7eOyvxp9t0Xwbbnx1Csyz","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_predict_on_array.py\n"}],"key":"cQoBitbL48"}],"key":"m1Z8vLVFyQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"    data = xr.DataArray(\n        data=np.arange(20 * 10).reshape(20, 10),\n        dims=(\"x\", \"y\"),\n        coords={\"x\": np.arange(20), \"y\": np.arange(10)}\n    ).astype(float)\n    \n    bgen = xbatcher.BatchGenerator(\n        data,\n        input_dims=dict(x=10, y=5),\n        input_overlap=dict(x=2, y=2),\n    )","key":"wjqPUsOsjK"},{"type":"output","id":"_4EsFmrUXaF8QWzDOhdxR","data":[],"key":"e7tSKDPrU9"}],"key":"bRR8L0o3nV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%%writefile -a test_predict_on_array.py\n\n@pytest.mark.parametrize(\n    \"model, output_tensor_dim, new_dim, resample_dim, expected_transform\",\n    [\n        # Case 1: Resampling - Downsampling with a subset model\n        (\n            SubsetAlongAxis(ax=1, n=5), # Corresponds to 'x' dim in batch\n            {'x': 5, 'y': 5},\n            [],\n            ['x'],\n            lambda da: da.isel(x=slice(0, 5)) # Expected: take first 5 elements of original 'x'\n        ),\n        # Case 2: Dimension reduction with a mean model\n        (\n            MeanAlongDim(ax=2), # Corresponds to 'y' dim in batch\n            {'x': 10},\n            [],\n            ['x'],\n            lambda da: da.mean(dim='y') # Expected: mean along original 'y'\n        ),\n    ]\n)\ndef test_predict_on_array_reassembly(\n    map_dataset_fixture,\n    model,\n    output_tensor_dim,\n    new_dim,\n    resample_dim,\n    expected_transform\n):\n    \"\"\"\n    Tests that predict_on_array correctly reassembles batches from different models.\n    \"\"\"\n    # --- Run the function under test ---\n    # Using a small batch_size to ensure multiple iterations\n    predicted_da, predicted_n = predict_on_array(\n        dataset=map_dataset_fixture,\n        model=model,\n        output_tensor_dim=output_tensor_dim,\n        new_dim=new_dim,\n        resample_dim=resample_dim,\n        batch_size=4 \n    )\n\n    # --- Manually calculate the expected result ---\n    bgen = map_dataset_fixture.generator\n    # 1. Create the expected output array structure\n    expected_size = _get_output_array_size(bgen, output_tensor_dim, new_dim, resample_dim)\n    expected_da = xr.DataArray(np.zeros(list(expected_size.values())), dims=list(expected_size.keys()))\n    expected_n = xr.full_like(expected_da, 0)\n\n    # 2. Manually iterate through batches and apply the same logic as the function\n    for i in range(len(map_dataset_fixture)):\n        batch_da = bgen[i]\n        \n        # Apply the same transformation the model would\n        transformed_batch = expected_transform(batch_da)\n        \n        # Get the rescaled indexer\n        old_indexer = bgen.batch_selectors[i]\n        new_indexer = {}\n        for key in old_indexer:\n            if key in resample_dim:\n                resample_ratio = output_tensor_dim[key] / bgen.input_dims[key]\n                new_indexer[key] = slice(\n                    int(old_indexer[key].start * resample_ratio),\n                    int(old_indexer[key].stop * resample_ratio)\n                )\n        \n        # Add the result to our manually calculated array\n        expected_da.loc[new_indexer] += transformed_batch.values\n        expected_n.loc[new_indexer] += 1\n\n    # --- Assert that the results are identical ---\n    # We test the raw summed output and the overlap counter array\n    xr.testing.assert_allclose(predicted_da, expected_da)\n    xr.testing.assert_allclose(predicted_n, expected_n)","key":"qbQLq3S3H2"},{"type":"output","id":"N51vPbZ9KwgHGCaTaWQUv","data":[{"output_type":"stream","name":"stdout","text":"Appending to test_predict_on_array.py\n"}],"key":"R1vCL8HaOq"}],"key":"cEAo2LM2fY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"!pytest -v test_predict_on_array.py","key":"LOtjJ37JXd"},{"type":"output","id":"iHUkEUQb-caZhXd1VPZPD","data":[{"output_type":"stream","name":"stdout","text":"\u001b[1m============================= test session starts ==============================\u001b[0m\r\nplatform linux -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- /home/runner/micromamba/envs/cookbook-dev/bin/python3.13\r\ncachedir: .pytest_cache\r\nrootdir: /home/runner/work/xbatcher-deep-learning/xbatcher-deep-learning/notebooks\r\nplugins: anyio-4.10.0\r\n\u001b[1mcollecting ... \u001b[0m"},{"output_type":"stream","name":"stdout","text":"\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollected 2 items                                                              \u001b[0m\r\n\r\ntest_predict_on_array.py::test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-\u003clambda\u003e] "},{"output_type":"stream","name":"stdout","text":"\u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\r\ntest_predict_on_array.py::test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-\u003clambda\u003e] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\r\n\r\n=================================== FAILURES ===================================\r\n\u001b[31m\u001b[1m_ test_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-\u003clambda\u003e] _\u001b[0m\r\n\r\nmap_dataset_fixture = \u003cxbatcher.loaders.torch.MapDataset object at 0x7fbeb9544590\u003e\r\nmodel = SubsetAlongAxis(), output_tensor_dim = {'x': 5, 'y': 5}, new_dim = []\r\nresample_dim = ['x'], expected_transform = \u003cfunction \u003clambda\u003e at 0x7fbeb9368860\u003e\r\n\r\n    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\r\n        \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel, output_tensor_dim, new_dim, resample_dim, expected_transform\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\r\n        [\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 1: Resampling - Downsampling with a subset model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                SubsetAlongAxis(ax=\u001b[94m1\u001b[39;49;00m, n=\u001b[94m5\u001b[39;49;00m), \u001b[90m# Corresponds to 'x' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.isel(x=\u001b[96mslice\u001b[39;49;00m(\u001b[94m0\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) \u001b[90m# Expected: take first 5 elements of original 'x'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 2: Dimension reduction with a mean model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                MeanAlongDim(ax=\u001b[94m2\u001b[39;49;00m), \u001b[90m# Corresponds to 'y' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m10\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.mean(dim=\u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[90m# Expected: mean along original 'y'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n        ]\u001b[90m\u001b[39;49;00m\r\n    )\u001b[90m\u001b[39;49;00m\r\n    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_predict_on_array_reassembly\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\r\n        map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n        model,\u001b[90m\u001b[39;49;00m\r\n        output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n        new_dim,\u001b[90m\u001b[39;49;00m\r\n        resample_dim,\u001b[90m\u001b[39;49;00m\r\n        expected_transform\u001b[90m\u001b[39;49;00m\r\n    ):\u001b[90m\u001b[39;49;00m\r\n    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\r\n    \u001b[33m    Tests that predict_on_array correctly reassembles batches from different models.\u001b[39;49;00m\r\n    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# --- Run the function under test ---\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# Using a small batch_size to ensure multiple iterations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n\u003e       predicted_da, predicted_n = predict_on_array(\u001b[90m\u001b[39;49;00m\r\n            dataset=map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n            model=model,\u001b[90m\u001b[39;49;00m\r\n            output_tensor_dim=output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n            new_dim=new_dim,\u001b[90m\u001b[39;49;00m\r\n            resample_dim=resample_dim,\u001b[90m\u001b[39;49;00m\r\n            batch_size=\u001b[94m4\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        )\u001b[90m\u001b[39;49;00m\r\n\u001b[1m\u001b[31mE       TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\u001b[0m\r\n\r\n\u001b[1m\u001b[31mtest_predict_on_array.py\u001b[0m:67: TypeError\r\n\u001b[31m\u001b[1m_ test_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-\u003clambda\u003e] _\u001b[0m\r\n\r\nmap_dataset_fixture = \u003cxbatcher.loaders.torch.MapDataset object at 0x7fbeb948a490\u003e\r\nmodel = MeanAlongDim(), output_tensor_dim = {'x': 10}, new_dim = []\r\nresample_dim = ['x'], expected_transform = \u003cfunction \u003clambda\u003e at 0x7fbeb9368e00\u003e\r\n\r\n    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\r\n        \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel, output_tensor_dim, new_dim, resample_dim, expected_transform\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\r\n        [\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 1: Resampling - Downsampling with a subset model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                SubsetAlongAxis(ax=\u001b[94m1\u001b[39;49;00m, n=\u001b[94m5\u001b[39;49;00m), \u001b[90m# Corresponds to 'x' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m5\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.isel(x=\u001b[96mslice\u001b[39;49;00m(\u001b[94m0\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m)) \u001b[90m# Expected: take first 5 elements of original 'x'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n            \u001b[90m# Case 2: Dimension reduction with a mean model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            (\u001b[90m\u001b[39;49;00m\r\n                MeanAlongDim(ax=\u001b[94m2\u001b[39;49;00m), \u001b[90m# Corresponds to 'y' dim in batch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n                {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[94m10\u001b[39;49;00m},\u001b[90m\u001b[39;49;00m\r\n                [],\u001b[90m\u001b[39;49;00m\r\n                [\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\r\n                \u001b[94mlambda\u001b[39;49;00m da: da.mean(dim=\u001b[33m'\u001b[39;49;00m\u001b[33my\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[90m# Expected: mean along original 'y'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n            ),\u001b[90m\u001b[39;49;00m\r\n        ]\u001b[90m\u001b[39;49;00m\r\n    )\u001b[90m\u001b[39;49;00m\r\n    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_predict_on_array_reassembly\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\r\n        map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n        model,\u001b[90m\u001b[39;49;00m\r\n        output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n        new_dim,\u001b[90m\u001b[39;49;00m\r\n        resample_dim,\u001b[90m\u001b[39;49;00m\r\n        expected_transform\u001b[90m\u001b[39;49;00m\r\n    ):\u001b[90m\u001b[39;49;00m\r\n    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\r\n    \u001b[33m    Tests that predict_on_array correctly reassembles batches from different models.\u001b[39;49;00m\r\n    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# --- Run the function under test ---\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        \u001b[90m# Using a small batch_size to ensure multiple iterations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n\u003e       predicted_da, predicted_n = predict_on_array(\u001b[90m\u001b[39;49;00m\r\n            dataset=map_dataset_fixture,\u001b[90m\u001b[39;49;00m\r\n            model=model,\u001b[90m\u001b[39;49;00m\r\n            output_tensor_dim=output_tensor_dim,\u001b[90m\u001b[39;49;00m\r\n            new_dim=new_dim,\u001b[90m\u001b[39;49;00m\r\n            resample_dim=resample_dim,\u001b[90m\u001b[39;49;00m\r\n            batch_size=\u001b[94m4\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\r\n        )\u001b[90m\u001b[39;49;00m\r\n\u001b[1m\u001b[31mE       TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\u001b[0m\r\n\r\n\u001b[1m\u001b[31mtest_predict_on_array.py\u001b[0m:67: TypeError\r\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\r\n\u001b[31mFAILED\u001b[0m test_predict_on_array.py::\u001b[1mtest_predict_on_array_reassembly[model0-output_tensor_dim0-new_dim0-resample_dim0-\u003clambda\u003e]\u001b[0m - TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\r\n\u001b[31mFAILED\u001b[0m test_predict_on_array.py::\u001b[1mtest_predict_on_array_reassembly[model1-output_tensor_dim1-new_dim1-resample_dim1-\u003clambda\u003e]\u001b[0m - TypeError: predict_on_array() missing 1 required positional argument: 'core_dim'\r\n\u001b[31m============================== \u001b[31m\u001b[1m2 failed\u001b[0m\u001b[31m in 1.57s\u001b[0m\u001b[31m ===============================\u001b[0m\r\n"}],"key":"zMYF02IufQ"}],"key":"cwnU5HNSVs"}],"key":"ECgMtaZzo6"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"How to Cite This Cookbook","url":"/notebooks/how-to-cite","group":"Preamble"}}},"domain":"http://localhost:3000"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Xbatcher for deep learning","authors":[{"nameParsed":{"literal":"The Project Pythia Community","given":"The Project Pythia","family":"Community"},"name":"The Project Pythia Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/projectpythia/xbatcher-deep-learning","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2024","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/xbatcher-deep-learning","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/inference-testing.ipynb"}],"title":"Testing model inference"},{"children":[{"file":"notebooks/functions.ipynb"}],"title":"Inference functions"}],"thumbnail":"/xbatcher-deep-learning/build/thumbnail-9d3533e06c20138ff98bb2ae816ee1eb.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/xbatcher-deep-learning/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Testing model inference"},{"slug":"notebooks.inference-testing","title":"Infer model on array","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Inference functions"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/xbatcher-deep-learning/build/manifest-B2B2E6A5.js";
import * as route0 from "/xbatcher-deep-learning/build/root-IB5726YR.js";
import * as route1 from "/xbatcher-deep-learning/build/routes/$-LXLHKVOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/xbatcher-deep-learning/build/entry.client-UNPC4GT3.js");</script></body></html>