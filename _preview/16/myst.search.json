{"version":"1","records":[{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers a workflow for using Xarray and xbatcher for deep learning applications. Specifically, it demonstrates a reusable workflow for recreating an xarray dataset from a deep learning model’s output, which can be used for further analysis or visualization.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Motivation"},"content":"This cookbook will be useful for data scientists and machine learning practitioners who want to leverage the power of xarray and xbatcher for their deep learning workflows. By the end of this cookbook, you will have gained skills in loading and processing Xarray datasets into a format suitable for deep learning using xbatcher and furthermore, you will learn how to recreate an Xarray dataset from the output of a deep learning model.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Authors"},"content":"Keenan Ganz, \n\nNabin Kalauni","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections - “xbatcher Fundamentals” and “Example Workflow”. The first section covers the foundational concepts and tools needed to work with xbatcher and xarray, while the second section provides a practical example of how to use these tools in a complete end-to-end workflow.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"type":"lvl3","url":"/#xbatcher-fundamentals","position":10},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"xbatcher Fundamentals","lvl2":"Structure"},"content":"The foundational content includes an overview of xbatcher, its key features, and how it integrates with xarray for efficient data handling in deep learning workflows. The first chapter covers using xbatcher to create batches of data from an xarray dataset whereas the second chapter focuses on recreating an xarray dataset from the output of a deep learning model.","type":"content","url":"/#xbatcher-fundamentals","position":11},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"type":"lvl3","url":"/#example-workflow","position":12},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Example Workflow","lvl2":"Structure"},"content":"Example workflow includes using xbatcher to create batches of data from an xarray dataset (ASTER Global Digital Elevation model), training an Autoencoder on this data, and then using xbatcher again to reassemble the model’s output into a new xarray dataset.","type":"content","url":"/#example-workflow","position":13},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"Xarray for Deep Learning Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/xbatcher-deep-learning repository: git clone https://github.com/ProjectPythia/xbatcher-deep-learning.git\n\nMove into the xbatcher-deep-learning directorycd xbatcher-deep-learning\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder"},"type":"lvl1","url":"/notebooks/autoencoder","position":0},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder"},"content":"\n\n","type":"content","url":"/notebooks/autoencoder","position":1},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/autoencoder#overview","position":2},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Overview"},"content":"In previous notebooks we have demonstrated how xbatcher converts both toy xarray objects into tensors and back again. In this notebook we incorporate these functions in an end-to-end workflow training an autoencoder on an elevation dataset. Once trained, the model is used to reconstruct two datasets:\n\nThe overall elevation tile\n\nA data cube of the autoencoder’s latent dimension","type":"content","url":"/notebooks/autoencoder#overview","position":3},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/autoencoder#prerequisites","position":4},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Prerequisites"},"content":"This notebook assumes familiarity with xarray, xbatcher, and torch. You don’t have to know how autoencoders work - we explain that when necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nArray indexing\n\nXbatcher fundamentals\n\nNecessary\n\nPassing data to models\n\nPyTorch fundamentals\n\nHelpful\n\nModel training loop\n\nAutoencoders\n\nHelpful\n\nMore information on how autoencoders work.\n\nTime to learn: 30 minutes.\n\nSystem requirements:\n\nWindows users may hit an import error on rioxarray (\n\nlink). If that happens, add import osgeo above import rioxarray and that seems to fix the issue.\n\n","type":"content","url":"/notebooks/autoencoder#prerequisites","position":5},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/autoencoder#imports","position":6},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Imports"},"content":"\n\nimport os\nif os.name == 'nt':\n    import osgeo\n\n# DL stuff\nimport matplotlib.pyplot as plt\nimport torch\n\ntorch.set_default_dtype(torch.float64)\n\n# Geospatial stuff\nimport xarray as xr\nimport xbatcher\nimport rioxarray\nfrom xbatcher.loaders.torch import MapDataset\n\n# Etc\nimport numpy as np\nfrom numpy.linalg import norm\nfrom matplotlib import pyplot as plt\n\n# Locals\nimport functions\nimport autoencoder\n\n","type":"content","url":"/notebooks/autoencoder#imports","position":7},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Get data"},"type":"lvl2","url":"/notebooks/autoencoder#get-data","position":8},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Get data"},"content":"\n\nWe will start by pulling a segment of NASADEM for Washington’s Olympic peninsula. The entire DEM is also available on NASA Earthdata and Planetary Computer.\n\n# Rasterio adds a blank edge. Trim these out.\ndem = rioxarray.open_rasterio(\"../ASTGTMV003_N47W124_dem.tif\")\ndem = dem.isel(y=slice(0, -1), x=slice(0, -1))\ndem = (dem - dem.min()) / (dem.max() - dem.min())\ndem\n\nNote that we rescaled the DEM to be in the range [0, 1]. This modification makes it easier for the autoencoder to train.\n\ndem.isel(band=0).plot.imshow(cmap=\"terrain\")\n\n","type":"content","url":"/notebooks/autoencoder#get-data","position":9},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Generate training examples"},"type":"lvl2","url":"/notebooks/autoencoder#generate-training-examples","position":10},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Generate training examples"},"content":"Here, we use xbatcher to generate patches of terrain. Even though we did not specify the band axis in the BatchGenerator, this axis still propagates to the output tensor’s second axis. Remember that torch data loaders add a batch dimension, so the tensor’s first axis is not relevant to the original xarray object.\n\nbgen_x = xbatcher.BatchGenerator(\n    dem,\n    input_dims=dict(x=32, y=32),\n    input_overlap=dict(x=16, y=16)\n)\n\nds = MapDataset(\n    X_generator=bgen_x\n)\n\nloader = torch.utils.data.DataLoader(ds, batch_size=16, shuffle=True)\n\nX = next(iter(loader))\n\nprint(\"Input tensor shape:\", X.shape)\n\n","type":"content","url":"/notebooks/autoencoder#generate-training-examples","position":11},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model setup"},"type":"lvl2","url":"/notebooks/autoencoder#model-setup","position":12},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model setup"},"content":"Here we instantiate the autoencoder class and verify that the output shape is what we expect. Autoencoders compress input data to a latent space and then reconstruct the input from the compressed representation. Usually, we are interested in the compressed result, but during training we are trying to recreate the input exactly. Therefore, the output tensor should match the shape of the input tensor.\n\nm = autoencoder.Autoencoder(base_channel_size=32, latent_dim=64, num_input_channels=1, width=32, height=32)\nopt = m._configure_optimizers()\n\nout = m(X)\nprint(out.shape)\nassert(out.shape == X.shape)\n\n","type":"content","url":"/notebooks/autoencoder#model-setup","position":13},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model training"},"type":"lvl2","url":"/notebooks/autoencoder#model-training","position":14},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Model training"},"content":"We aren’t using pytorch-lightning and load a pre-trained model here to keep the notebook environment lean. For your project, we highly recommend using a framework to abstract away much of the boilerplate code below.\n\ndef train_one_epoch(epoch_index):\n    last_loss = 0.\n    running_loss = 0.\n    \n    for i, batch in enumerate(tqdm(loader)):\n        # Zero your gradients for every batch!\n        opt.zero_grad()\n\n        # Make predictions for this batch\n        outputs = m(batch)\n\n        # Compute the loss and its gradients\n        loss = m._get_reconstruction_loss(batch, outputs)\n        loss.backward()\n        running_loss += loss.item()\n\n        # Adjust learning weights\n        opt.step()\n\n    return running_loss / len(loader)\n\nn_epochs = 5\nfor i_epoch in range(n_epochs):\n    loss = train_one_epoch(i_epoch)\n    print(f\"Epoch {i_epoch+1:>3}: {loss:.3e}\")\n\ntorch.save(m.state_dict(), \"../autoencoder.torch\")\n\nDanger\n\nThis model is certainly overfitted. For brevity we have omitted a validation dataset, which is essential for building models that generalize well on unseen data.\n\nm.load_state_dict(torch.load(\"../autoencoder.torch\", weights_only=True))\n\nm.eval()\nn_examples = 4\ninputs = next(iter(loader))\noutputs = m(inputs)\n\ninputs = inputs.detach().cpu().numpy()\noutputs = outputs.detach().cpu().numpy()\n\nfig, axes = plt.subplots(2, n_examples)\n\nfor i_col in range(n_examples):\n    axes[0, i_col].imshow(inputs[i_col, 0, ...])\n    axes[1, i_col].imshow(outputs[i_col, 0, ...])\n\nfor a in axes.flat:\n    a.set_xticks([])\n    a.set_yticks([])\n\naxes[0, 0].set_ylabel(\"Original patch\")\naxes[1, 0].set_ylabel(\"Reconstruction\")\n\nfig.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/autoencoder#model-training","position":15},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 1: Getting the full array back"},"type":"lvl2","url":"/notebooks/autoencoder#reconstruction-1-getting-the-full-array-back","position":16},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 1: Getting the full array back"},"content":"Suppose we would like to evaluate how the autoencoder does on reconstructing the entire terrain patch by combining outputs across all input patches. To do so we can use the predict_on_array function described in the previous notebook. Our model outputs tensors with shape (band=1, x=32, y=32). We need to specify each of these axes in the call to predict_on_array. band does not change size and is not used by the BatchGenerator, so it goes in core_dim. Both x and y are used by the BatchGenerator, so although they do not change size they still go in resample_dim. That accounts for all tensor axes, so we can leave the new_dim argument as an empty list.\n\ndem_reconst = functions.predict_on_array(\n    dataset=ds,\n    model=m,\n    output_tensor_dim=dict(band=1, y=32, x=32),\n    new_dim=[],\n    core_dim=[\"band\"],\n    resample_dim=[\"x\", \"y\"],\n    progress_bar=False\n)\n\ndem_reconst.isel(band=0).plot.imshow(cmap=\"terrain\")\n\nThat certainly looks like the original DEM. Let’s try plotting the error in the reconstruction.\n\nerr = (dem_reconst - dem)\nerr.isel(band=0).plot.imshow()\nplt.show()\n\nerr.plot.hist()\nplt.show()\n\nNot bad!\n\n","type":"content","url":"/notebooks/autoencoder#reconstruction-1-getting-the-full-array-back","position":17},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 2: Getting the latent dimension"},"type":"lvl2","url":"/notebooks/autoencoder#reconstruction-2-getting-the-latent-dimension","position":18},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Reconstruction 2: Getting the latent dimension"},"content":"A common application of autoencoders is to use the latent dimension for some application. Let’s turn our autoencoder’s predictions into a data cube. To do so we will modify the batch generator to not have overlapping windows. We also have to slightly clip the size of the input DEM. This is because we are effectively downscaling the spatial axes by a factor of 32. Since 3600 / 32 is not an integer, predict_on_array will not know how to rescale the array size. So, we have to clip the DEM to the nearest integer multiple of 32. In this case the nearest multiple is 3584, which we achieve by clipping 8 pixels from each side.\n\nbgen_no_overlap = xbatcher.BatchGenerator(\n    dem.isel(x=slice(8, -8), y=slice(8, -8)),\n    input_dims=dict(x=32, y=32),\n    input_overlap=dict(x=0, y=0)\n)\n\nds_no_overlap = MapDataset(\n    X_generator=bgen_no_overlap\n)\n\nloader = torch.utils.data.DataLoader(ds_no_overlap, batch_size=16, shuffle=True)\n\nex_input = next(iter(loader))\n\n# Same as before\nprint(\"Input shape:\", ex_input.shape)\n\nNext we will write a function that the calls the encoder arm of the autoencoder and adds a fake x and y dimension.\n\ndef infer_with_encoder(x):\n    return m.encoder(x)[:, None, None, :]\n\nex_output = infer_with_encoder(ex_input)\nprint(\"Output shape:\", ex_output.shape)\n\nTo be clear, we started with the usual x/y/band tensor from the input dataset, and end up with a tensor that has singleton x/y dimensions and a new, 64-element channel dimension.\n\nWe can go through the same process as before to see how we put together the predict_on_array call. Both the x and y dimensions change size and are used by the batch generator, so they go in resample_dims. The remaining dimension, channel, is a new dimension and goes in the new_dim list.\n\nlatent_dim_cube = functions.predict_on_array(\n    dataset=ds_no_overlap,\n    model=infer_with_encoder,\n    output_tensor_dim=dict(y=1, x=1, channel=64),\n    new_dim=[\"channel\"],\n    core_dim=[],\n    resample_dim=[\"x\", \"y\"],\n    progress_bar=False\n)\n\nlatent_dim_cube\n\nNote that despite substantially re-arranging the input DataArray, we have retained the coordinate information at a resampled resolution.\n\nIf we simply sum the output over the channel dimension, we see that the encoder clearly distinguishes between upland and lowland areas.\n\nlatent_dim_cube.sum(dim=\"channel\").plot.imshow()\n\nAs a final demonstration of this workflow, let’s compute the cosine similarity of each of the below pixels with the latent encoding of \n\nMt. Olympus.\n\nolympus = dict(x=-123.7066, y=47.7998)\nolympus_latent = latent_dim_cube.sel(**olympus, method=\"nearest\")\nolympus_latent\n\ndef numpy_cosine_similarity(x, y):\n    return np.dot(x, y)/(norm(x)*norm(y))\n\nolympus_similarity = xr.apply_ufunc(\n    numpy_cosine_similarity,\n    latent_dim_cube,\n    input_core_dims = [[\"channel\"]],\n    output_core_dims = [[]],\n    vectorize=True,\n    kwargs=dict(y=olympus_latent.data)\n)\n\nolympus_similarity.plot.imshow()\nplt.scatter(olympus[\"x\"], olympus[\"y\"], marker=\"*\", c=\"purple\", edgecolor=\"black\", s=200)\nplt.title(\"Cosine similarity with Mt. Olympus, WA\")\nplt.show()\n\nSimilarly, we can identify foothills with similar topography to Grisdale, WA.\n\ngrisdale = dict(y=47.356625678465925, x=-123.61183314426664)\ngrisdale_latent = latent_dim_cube.sel(**grisdale, method=\"nearest\")\n\ngrisdale_similarity = xr.apply_ufunc(\n    numpy_cosine_similarity,\n    latent_dim_cube,\n    input_core_dims = [[\"channel\"]],\n    output_core_dims = [[]],\n    vectorize=True,\n    kwargs=dict(y=grisdale_latent.data)\n)\n\ngrisdale_similarity.plot.imshow()\nplt.scatter(grisdale[\"x\"], grisdale[\"y\"], marker=\"*\", c=\"purple\", edgecolor=\"black\", s=200)\nplt.title(\"Cosine similarity with Grisdale, WA\")\nplt.show()\n\nThis result is admittedly very similar to if we had just selected elevation bands :)\n\n\n\n","type":"content","url":"/notebooks/autoencoder#reconstruction-2-getting-the-latent-dimension","position":19},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/autoencoder#summary","position":20},{"hierarchy":{"lvl1":"Using xbatcher to train an autoencoder","lvl2":"Summary"},"content":"Our goal with this notebook has been to show how xbatcher supports linking xarray objects with deep learning models, and with converting model output back into labeled xarray objects. We have demonstrated two examples of reconstructing model output, both when tensor shape changes and when it does not.\n\nIf you encounter any issues, please open an issue on the GitHub repository for this cookbook. Other feedback is welcome!","type":"content","url":"/notebooks/autoencoder#summary","position":21},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects"},"type":"lvl1","url":"/notebooks/xbatcher-dataloading","position":0},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects"},"content":"\n\n","type":"content","url":"/notebooks/xbatcher-dataloading","position":1},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#overview","position":2},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Overview"},"content":"Working with large, multi-dimensional datasets, common in fields like climate science and oceanography, presents a significant challenge when preparing data for machine learning models. The xbatcher library is designed to simplify this preprocessing step by serving as a bridge between the labeled, multi-dimensional data structures of xarray and the tensor-based inputs required by deep learning frameworks such as PyTorch and TensorFlow.\n\nThis guide provides an introduction to the fundamentals of xbatcher. We will cover how to create a BatchGenerator, customize it for specific needs, and prepare the resulting data for integration with a PyTorch model.","type":"content","url":"/notebooks/xbatcher-dataloading#overview","position":3},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#prerequisites","position":4},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nArray indexing\n\nDatasets and DataLoaders\n\nHelpful\n\nBatching data\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#prerequisites","position":5},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#imports","position":6},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport numpy as np\nimport torch\nimport xbatcher\nfrom xbatcher.loaders.torch import MapDataset, IterableDataset\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#imports","position":7},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Creating a Sample Dataset"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#creating-a-sample-dataset","position":8},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Creating a Sample Dataset"},"content":"To begin, we will create a sample xarray.Dataset. This allows us to focus on the mechanics of xbatcher without the overhead of a specific real-world dataset. This sample can be replaced by any xarray.Dataset loaded from a file (e.g., NetCDF, Zarr).\n\nds = xr.Dataset(\n    {\n        \"temperature\": ((\"x\", \"y\", \"time\"), np.random.rand(100, 100, 50)),\n        \"precipitation\": ((\"x\", \"y\", \"time\"), np.random.rand(100, 100, 50)),\n    },\n    coords={\n        \"x\": np.arange(100),\n        \"y\": np.arange(100),\n        \"time\": np.arange(50),\n    },\n)\nds\n\nThe dataset contains two variables, temperature and precipitation, and three dimensions: x, y, and time. We will now use xbatcher to generate batches from this dataset.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#creating-a-sample-dataset","position":9},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"The BatchGenerator"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#the-batchgenerator","position":10},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"The BatchGenerator"},"content":"The BatchGenerator is the core component of xbatcher. It is a Python generator that yields batches of data from an xarray object.\n\nbgen = xbatcher.BatchGenerator(ds, input_dims={\"x\": 10, \"y\": 10})\n\nThe BatchGenerator is initialized with the dataset and the input_dims parameter. input_dims specifies the size of the batches along each dimension. In this case, we are creating batches of size 10x10 along the x and y dimensions. The time dimension is not specified, so xbatcher will yield batches that include all time steps.\n\nLet’s inspect the first batch generated.\n\nfirst_batch = next(iter(bgen))\nfirst_batch\n\n Horizontal lines  Vertical lines  Colored Rectangle  Horizontal lines  Vertical lines  Colored Rectangle  Horizontal lines  Vertical lines  Colored Rectangle  Text \n\nThe first batch has dimensions x=10, y=10, and time=50, as expected. The BatchGenerator will yield 100 batches in total (10 batches in the x-direction * 10 batches in the y-direction).\n\nprint(f\"The BatchGenerator contains {len(bgen)} batches.\")\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#the-batchgenerator","position":11},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Overlapping Batches with input_overlap"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#overlapping-batches-with-input-overlap","position":12},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Overlapping Batches with input_overlap"},"content":"In many applications, it is useful to have overlapping batches to provide context from neighboring data points. The input_overlap parameter allows for this.\n\nbgen_overlap = xbatcher.BatchGenerator(\n    ds, \n    input_dims={\"x\": 10, \"y\": 10}, \n    input_overlap={\"x\": 2, \"y\": 2}\n)\nfirst_batch_overlap = next(iter(bgen_overlap))\nfirst_batch_overlap\n\nThe input_overlap parameter specifies the number of elements to overlap between consecutive batches. The size of the batches themselves does not change. Let’s verify this by inspecting the coordinates of the first two batches.\n\nprint(f\"Batch 1 y-coords: {bgen_overlap[0].y.values}, Batch 1 x-coords: {bgen_overlap[0].x.values}\")\nprint(f\"Batch 2 y-coords: {bgen_overlap[1].y.values}, Batch 2 x-coords: {bgen_overlap[1].x.values}\")\nprint(f\"Batch 3 y-coords: {bgen_overlap[2].y.values}, Batch 3 x-coords: {bgen_overlap[2].x.values}\")\nprint(f\"Batch 13 y-coords: {bgen_overlap[12].y.values}, Batch 13 x-coords: {bgen_overlap[12].x.values}\")\nprint(f\"Batch 14 y-coords: {bgen_overlap[13].y.values}, Batch 11 x-coords: {bgen_overlap[13].x.values}\")\n\nAs you can see, the second batch starts at y=8, which is an overlap of 2 elements with the first batch, which ends at y=9.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#overlapping-batches-with-input-overlap","position":13},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Integration with PyTorch"},"type":"lvl2","url":"/notebooks/xbatcher-dataloading#integration-with-pytorch","position":14},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl2":"Integration with PyTorch"},"content":"xbatcher provides MapDataset and IterableDataset to wrap the BatchGenerator for use with PyTorch.\n\n","type":"content","url":"/notebooks/xbatcher-dataloading#integration-with-pytorch","position":15},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl3":"MapDataset vs. IterableDataset","lvl2":"Integration with PyTorch"},"type":"lvl3","url":"/notebooks/xbatcher-dataloading#mapdataset-vs-iterabledataset","position":16},{"hierarchy":{"lvl1":"Loading Batches from Xarray Objects","lvl3":"MapDataset vs. IterableDataset","lvl2":"Integration with PyTorch"},"content":"MapDataset: Implements __getitem__ and __len__, allowing for random access to data samples. This is the most common type of dataset in PyTorch.\n\nIterableDataset: Implements __iter__, and is suitable for very large datasets that may not fit into memory, as it streams data.\n\nWe will use MapDataset for this example.\n\nbgen[0].temperature.shape\nbgen[0].precipitation.shape\n\ndef patch_to_tensor(patch):\n    temp_patch = torch.tensor(patch.temperature.data)\n    prcp_patch = torch.tensor(patch.precipitation.data)\n    stacked_patch = torch.stack((temp_patch, prcp_patch), dim=0)\n    patch = stacked_patch\n    patch = torch.nan_to_num(patch)\n    # patch = torch.unsqueeze(patch, 0)\n    patch = patch.float()\n    return patch\n\nmap_ds = MapDataset(bgen, transform=patch_to_tensor)\n\nThe MapDataset can then be used with a PyTorch DataLoader, which provides utilities for shuffling, batching, and multiprocessing.\n\ndataloader = torch.utils.data.DataLoader(map_ds, batch_size=4)\n\nInspecting a batch from the DataLoader reveals a batch of PyTorch tensors.\n\ntorch_batch = next(iter(dataloader))\ntorch_batch.shape\n\nThe DataLoader has stacked 4 of the xbatcher batches, creating a new batch dimension of size 4. The data is now ready for use in a PyTorch model.\n\nIn the next notebook, we will explore how to reconstruct an xarray.Dataset from a model’s output.","type":"content","url":"/notebooks/xbatcher-dataloading#mapdataset-vs-iterabledataset","position":17},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs"},"type":"lvl1","url":"/notebooks/xbatcher-reconstruction","position":0},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs"},"content":"\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction","position":1},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#overview","position":2},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Overview"},"content":"This notebook addresses the process of reconstructing an xarray.DataArray from the output of a machine learning model. While the previous notebook focused on generating batches from xarray objects, this guide details the reverse process: assembling model outputs back into a coherent, labeled xarray object. This is a common requirement in scientific machine learning workflows, where the model output needs to be analyzed in its original spatial or temporal context.\n\nWe will examine a function that reassembles model outputs, including a detailed look at how an internal API of xbatcher can be used to map batch outputs back to their original coordinates.\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#overview","position":3},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#prerequisites","position":4},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nArray indexing\n\nLoading Batches from Xarray\n\nHelpful\n\nPyTorch DataLoader API\n\nPyTorch fundamentals\n\nHelpful\n\nModel training loop\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#prerequisites","position":5},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#imports","position":6},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport numpy as np\nimport xbatcher\nfrom xbatcher.loaders.torch import MapDataset\n\nfrom dummy_models import ExpandAlongAxis\n\nfrom functions import predict_on_array\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#imports","position":7},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Setup: Data, Batches, and a Dummy Model"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#setup-data-batches-and-a-dummy-model","position":8},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Setup: Data, Batches, and a Dummy Model"},"content":"We will begin by creating a sample xarray.DataArray and a BatchGenerator. We will also instantiate a dummy model that transforms the data, simulating a common machine learning scenario where the output dimensions differ from the input dimensions (e.g., super-resolution).\n\nda = xr.DataArray(\n    data=np.random.rand(50, 40).astype(np.float32),\n    dims=(\"x\", \"y\"),\n    coords={\"x\": np.arange(50), \"y\": np.arange(40)},\n)\nda\n\nNext, we create the BatchGenerator.\n\nbgen = xbatcher.BatchGenerator(da, input_dims={\"x\": 10, \"y\": 10})\n\nFor the model, we will use ExpandAlongAxis from dummy_models.py. This model upsamples the input along a specified axis, changing the dimensions of the data.\n\n# The model will expand the 'x' dimension by a factor of 2\nmodel = ExpandAlongAxis(ax=1, n_repeats=2)\n\n","type":"content","url":"/notebooks/xbatcher-reconstruction#setup-data-batches-and-a-dummy-model","position":9},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Reconstructing the Dataset"},"type":"lvl2","url":"/notebooks/xbatcher-reconstruction#reconstructing-the-dataset","position":10},{"hierarchy":{"lvl1":"Reconstructing Xarray Datasets from Model Outputs","lvl2":"Reconstructing the Dataset"},"content":"We will now use the predict_on_array function to reconstruct the dataset. The most important part of using this function is correctly specifying the arguments new_dim, core_dim, and resample_dim. These lists all contain dimensions given in output_tensor_dim and help us get an idea of how model output compares to the input data. In general:\n\nnew_dim: Tensor dimensions that do not appear at all in the original xarray object.\n\ncore_dim: Tensor dimensions that are present in the original xarray object, but are not used for batch generation. We assume that all elements of this dimension in the xarray object flow through the model to the output. Coordinates are simply copied from the original xarray object.\n\nresample_dim: Tensor dimensions that are present in the original xarray object and used for batch generation. These dimensions are allowed to change size (but see below note) and coordinates are resampled accordingly in the reconstructed array.\n\nLet’s apply these rules to our present example. The batch generator creates tensors of size (x=10, y=10) and the dummy model makes tensors of size (x=20, y=10). In this case, all tensor dimensions are present in the original data array and are used for batch generation. Therefore, both x and y go in resample_dim. Now that all tensor dimensions are accounted for, we can simply leave new_dim and core_dim as empty lists.\n\nChanging dimension sizes\n\nDimensions in resample_dim must upsample or downsample by a factor that implies an integer size in the output data array. For example, in this example we generated tensors of size (x=10, y=10) and the model generates tensors of size (x=20, y=10). This implies that we are upsampling x by a factor of 2. The original data array has size of 50 in the x dimension, and 50 * 2 = 100 is an integer, so this is allowed.\n\nWhat if, for some reason, the batch generator made tensors of size (x=7, y=7) and the model generated tensors of size (x=10, y=10)? The resampling factor becomes 10/7, and the implied output data array size is (50 * 10/7) = 72.43. This is not an integer, so predict_on_array will throw an error.\n\nmap_dataset = MapDataset(bgen)\nreconstructed_da = predict_on_array(\n    dataset=map_dataset,\n    model=model,\n    output_tensor_dim={\"x\": 20, \"y\": 10}, # The model doubles the x-dimension\n    new_dim=[],\n    core_dim=[],\n    resample_dim=[\"x\", \"y\"],\n    batch_size=4,\n    progress_bar=False\n)\nreconstructed_da\n\nThe reconstructed DataArray has the upsampled x dimension. We can compare its shape to the original.\n\nprint(f\"Original shape: {da.shape}\")\nprint(f\"Reconstructed shape: {reconstructed_da.shape}\")\n\nThe reconstructed array has twice the number of elements in the x dimension, as expected.","type":"content","url":"/notebooks/xbatcher-reconstruction#reconstructing-the-dataset","position":11}]}